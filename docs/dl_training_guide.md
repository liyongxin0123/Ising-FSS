# ä¼Šè¾›æ¨¡å‹æ„å‹æ•°æ® - æ·±åº¦å­¦ä¹ è®­ç»ƒæŒ‡å—

## ğŸ“Š æ•°æ®é›†æ¦‚è¿°

### ç”Ÿæˆçš„æ•°æ®ç»“æ„

```python
dataset = {
    'configs': (n_h, n_T, n_configs, L, L),  # æ„å‹æ•°æ®
    'energy': (n_h, n_T, n_configs),          # èƒ½é‡
    'magnetization': (n_h, n_T, n_configs),   # ç£åŒ–å¼ºåº¦
    'temperatures': (n_T,),                   # æ¸©åº¦æ•°ç»„
    'fields': (n_h,),                         # ç£åœºæ•°ç»„
    'parameters': {...}                       # å…ƒæ•°æ®
}
```

### è®ºæ–‡æ ‡å‡†é…ç½®

| å‚æ•° | å€¼ | è¯´æ˜ |
|-----|---|------|
| L | 32 | æ™¶æ ¼å°ºå¯¸ |
| n_T | 65 | æ¸©åº¦ç‚¹æ•° |
| n_h | 65 | ç£åœºç‚¹æ•° |
| n_configs | 1024 | æ¯ç‚¹æ„å‹æ•° |
| **æ€»æ„å‹æ•°** | **4,321,280** | 65Ã—65Ã—1024 |

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç”Ÿæˆæ•°æ®

#### CPUç‰ˆæœ¬ï¼ˆé€‚åˆå°è§„æ¨¡ï¼‰

```python
from ising_config_saver import IsingConfigGenerator

# åˆ›å»ºç”Ÿæˆå™¨
generator = IsingConfigGenerator(
    L=32,
    T_range=(1.0, 5.0),
    h_range=(-2.0, 2.0),
    n_T=65,
    n_h=65,
    n_configs=1024
)

# ç”Ÿæˆå®Œæ•´æ•°æ®é›†
dataset = generator.generate_full_dataset(
    equilibration=8192,
    sampling_interval=8,
    save_path='ising_data.h5'
)
```

**é¢„æœŸæ—¶é—´**: 2-4å°æ—¶

#### GPUç‰ˆæœ¬ï¼ˆæ¨èï¼‰

```python
from gpu_config_generator import GPUIsingConfigGenerator

# GPUç”Ÿæˆå™¨
generator = GPUIsingConfigGenerator(
    L=32,
    T_range=(1.0, 5.0),
    h_range=(-2.0, 2.0),
    n_T=65,
    n_h=65,
    n_configs=1024
)

# ç”Ÿæˆï¼ˆå¿«10-50å€ï¼ï¼‰
dataset = generator.generate_full_dataset(
    equilibration=8192,
    sampling_interval=8,
    save_path='ising_data_gpu.h5',
    save_every_n_fields=10  # å¢é‡ä¿å­˜
)
```

**é¢„æœŸæ—¶é—´**: 5-15åˆ†é’Ÿ âš¡

### 2. åŠ è½½æ•°æ®

```python
from ising_config_saver import load_configs_hdf5

dataset = load_configs_hdf5('ising_data.h5')

print(f"æ„å‹å½¢çŠ¶: {dataset['configs'].shape}")
print(f"æ¸©åº¦èŒƒå›´: {dataset['temperatures'][[0, -1]]}")
print(f"ç£åœºèŒƒå›´: {dataset['fields'][[0, -1]]}")
```

---

## ğŸ§  æ·±åº¦å­¦ä¹ åº”ç”¨

### åº”ç”¨1: å˜åˆ†è‡ªç¼–ç å™¨ (VAE)

å‚è€ƒè®ºæ–‡æ–¹æ³•ï¼Œè®­ç»ƒVAEæå–æ½œåœ¨ç‰¹å¾ã€‚

#### æ•°æ®å‡†å¤‡

```python
import h5py
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader

class IsingDataset(Dataset):
    """ä¼Šè¾›æ„å‹æ•°æ®é›†ï¼ˆPyTorchï¼‰"""
    
    def __init__(self, hdf5_path, normalize=True):
        with h5py.File(hdf5_path, 'r') as f:
            # åŠ è½½æ‰€æœ‰æ„å‹å¹¶å±•å¹³
            configs = f['configs'][:]  # (n_h, n_T, n_configs, L, L)
            self.configs = configs.reshape(-1, configs.shape[-2], configs.shape[-1])
            
            # æ ‡ç­¾ï¼ˆæ¸©åº¦å’Œç£åœºï¼‰
            temps = f['temperatures'][:]
            fields = f['fields'][:]
            
            # ä¸ºæ¯ä¸ªæ„å‹åˆ›å»º(T,h)æ ‡ç­¾
            labels = []
            for h in fields:
                for T in temps:
                    labels.extend([(T, h)] * configs.shape[2])
            self.labels = np.array(labels)
        
        # å½’ä¸€åŒ–åˆ°[0,1]
        if normalize:
            self.configs = (self.configs + 1) / 2.0
        
        print(f"åŠ è½½ {len(self.configs)} ä¸ªæ„å‹")
    
    def __len__(self):
        return len(self.configs)
    
    def __getitem__(self, idx):
        config = torch.FloatTensor(self.configs[idx]).unsqueeze(0)  # (1, L, L)
        label = torch.FloatTensor(self.labels[idx])
        return config, label

# åˆ›å»ºæ•°æ®åŠ è½½å™¨
dataset = IsingDataset('ising_data.h5')
train_loader = DataLoader(dataset, batch_size=128, shuffle=True, num_workers=4)
```

#### VAEæ¨¡å‹ï¼ˆç®€åŒ–ç‰ˆï¼‰

```python
import torch.nn as nn

class IsingVAE(nn.Module):
    """ä¼Šè¾›æ„å‹VAE"""
    
    def __init__(self, latent_dim=10):
        super().__init__()
        
        # ç¼–ç å™¨: (1, 32, 32) -> latent_dim
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 32, 4, 2, 1),  # -> (32, 16, 16)
            nn.ReLU(),
            nn.Conv2d(32, 64, 4, 2, 1),  # -> (64, 8, 8)
            nn.ReLU(),
            nn.Conv2d(64, 128, 4, 2, 1), # -> (128, 4, 4)
            nn.ReLU(),
            nn.Flatten()
        )
        
        self.fc_mu = nn.Linear(128 * 4 * 4, latent_dim)
        self.fc_logvar = nn.Linear(128 * 4 * 4, latent_dim)
        
        # è§£ç å™¨: latent_dim -> (1, 32, 32)
        self.fc_decode = nn.Linear(latent_dim, 128 * 4 * 4)
        
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(128, 64, 4, 2, 1),
            nn.ReLU(),
            nn.ConvTranspose2d(64, 32, 4, 2, 1),
            nn.ReLU(),
            nn.ConvTranspose2d(32, 1, 4, 2, 1),
            nn.Sigmoid()
        )
    
    def encode(self, x):
        h = self.encoder(x)
        mu = self.fc_mu(h)
        logvar = self.fc_logvar(h)
        return mu, logvar
    
    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std
    
    def decode(self, z):
        h = self.fc_decode(z).view(-1, 128, 4, 4)
        return self.decoder(h)
    
    def forward(self, x):
        mu, logvar = self.encode(x)
        z = self.reparameterize(mu, logvar)
        recon = self.decode(z)
        return recon, mu, logvar

# VAEæŸå¤±å‡½æ•°
def vae_loss(recon_x, x, mu, logvar):
    # é‡æ„æŸå¤±
    BCE = nn.functional.binary_cross_entropy(recon_x, x, reduction='sum')
    
    # KLæ•£åº¦
    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
    
    return BCE + KLD
```

#### è®­ç»ƒå¾ªç¯

```python
# åˆå§‹åŒ–
model = IsingVAE(latent_dim=10).cuda()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

# è®­ç»ƒ
for epoch in range(50):
    model.train()
    train_loss = 0
    
    for batch_idx, (data, labels) in enumerate(train_loader):
        data = data.cuda()
        
        optimizer.zero_grad()
        recon, mu, logvar = model(data)
        loss = vae_loss(recon, data, mu, logvar)
        
        loss.backward()
        train_loss += loss.item()
        optimizer.zero_grad()
    
    print(f'Epoch {epoch}: Loss = {train_loss / len(train_loader.dataset):.4f}')

# ä¿å­˜æ¨¡å‹
torch.save(model.state_dict(), 'ising_vae.pth')
```

---

### åº”ç”¨2: ç›¸å˜åˆ†ç±»å™¨

è®­ç»ƒåˆ†ç±»å™¨è¯†åˆ«ä¸åŒç›¸ï¼ˆé“ç£/é¡ºç£ï¼‰ã€‚

```python
class IsingClassifier(nn.Module):
    """ä¼Šè¾›ç›¸åˆ†ç±»å™¨"""
    
    def __init__(self, num_classes=3):  # é“ç£+, é¡ºç£, é“ç£-
        super().__init__()
        
        self.features = nn.Sequential(
            nn.Conv2d(1, 32, 3, 1, 1),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 3, 1, 1),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(64, 128, 3, 1, 1),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d(1)
        )
        
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(64, num_classes)
        )
    
    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x

# æ ‡ç­¾ç”Ÿæˆï¼ˆåŸºäºæ¸©åº¦ï¼‰
def get_phase_label(T, Tc=2.269):
    if T < Tc * 0.8:
        return 0  # é“ç£ç›¸
    elif T < Tc * 1.2:
        return 1  # ä¸´ç•ŒåŒº
    else:
        return 2  # é¡ºç£ç›¸
```

---

### åº”ç”¨3: ä¸´ç•Œæ¸©åº¦é¢„æµ‹

ä½¿ç”¨ç¥ç»ç½‘ç»œç›´æ¥ä»æ„å‹é¢„æµ‹æ¸©åº¦ã€‚

```python
class TempPredictor(nn.Module):
    """æ¸©åº¦é¢„æµ‹å™¨"""
    
    def __init__(self):
        super().__init__()
        
        self.net = nn.Sequential(
            nn.Conv2d(1, 32, 5, 1, 2),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 3, 1, 1),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(64, 128, 3, 1, 1),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 1)  # å›å½’è¾“å‡º
        )
    
    def forward(self, x):
        return self.net(x)

# è®­ç»ƒï¼ˆMSEæŸå¤±ï¼‰
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters())

for data, labels in train_loader:
    data = data.cuda()
    temps = labels[:, 0].cuda()  # æ¸©åº¦æ ‡ç­¾
    
    pred_temps = model(data).squeeze()
    loss = criterion(pred_temps, temps)
    
    loss.backward()
    optimizer.step()
    optimizer.zero_grad()
```

---

## ğŸ“ˆ æ•°æ®å¯è§†åŒ–

### å¯è§†åŒ–æ„å‹

```python
import matplotlib.pyplot as plt

def plot_configs_grid(dataset, n_temps=5, n_fields=5):
    """ç»˜åˆ¶(T,h)ç½‘æ ¼çš„æ„å‹"""
    configs = dataset['configs']
    temps = dataset['temperatures']
    fields = dataset['fields']
    
    # å‡åŒ€é‡‡æ ·
    t_indices = np.linspace(0, len(temps)-1, n_temps, dtype=int)
    h_indices = np.linspace(0, len(fields)-1, n_fields, dtype=int)
    
    fig, axes = plt.subplots(n_fields, n_temps, figsize=(15, 12))
    
    for i, h_idx in enumerate(h_indices):
        for j, t_idx in enumerate(t_indices):
            config = configs[h_idx, t_idx, 0]  # ç¬¬ä¸€ä¸ªæ„å‹
            
            axes[i, j].imshow(config, cmap='gray', vmin=-1, vmax=1)
            axes[i, j].axis('off')
            
            if i == 0:
                axes[i, j].set_title(f'T={temps[t_idx]:.2f}', fontsize=10)
            if j == 0:
                axes[i, j].set_ylabel(f'h={fields[h_idx]:.2f}', fontsize=10)
    
    plt.tight_layout()
    return fig

# ä½¿ç”¨
fig = plot_configs_grid(dataset)
plt.savefig('config_grid.png', dpi=150, bbox_inches='tight')
```

### ç›¸å›¾å¯è§†åŒ–

```python
def plot_phase_diagram(dataset):
    """ç»˜åˆ¶(T,h)ç›¸å›¾"""
    configs = dataset['configs']
    temps = dataset['temperatures']
    fields = dataset['fields']
    
    # è®¡ç®—å¹³å‡ç£åŒ–å¼ºåº¦
    avg_mag = np.mean(np.abs(configs), axis=(2, 3, 4))
    
    plt.figure(figsize=(10, 8))
    plt.imshow(avg_mag, extent=[temps[0], temps[-1], fields[0], fields[-1]],
              aspect='auto', origin='lower', cmap='RdBu_r')
    plt.colorbar(label='å¹³å‡ç£åŒ–å¼ºåº¦ |M|')
    plt.xlabel('æ¸©åº¦ T')
    plt.ylabel('å¤–éƒ¨ç£åœº h')
    plt.title('ä¼Šè¾›æ¨¡å‹ç›¸å›¾')
    
    # æ ‡æ³¨ä¸´ç•Œæ¸©åº¦
    Tc = 2.269
    plt.axvline(Tc, color='white', linestyle='--', label=f'$T_c$ = {Tc}')
    plt.legend()
    
    return plt.gcf()
```

---

## ğŸ”§ é«˜çº§ç”¨æ³•

### æ•°æ®å¢å¼º

```python
def augment_config(config):
    """æ„å‹æ•°æ®å¢å¼º"""
    # éšæœºæ—‹è½¬ï¼ˆ90åº¦çš„å€æ•°ï¼‰
    k = np.random.randint(0, 4)
    config = np.rot90(config, k)
    
    # éšæœºç¿»è½¬
    if np.random.rand() > 0.5:
        config = np.flip(config, axis=0)
    if np.random.rand() > 0.5:
        config = np.flip(config, axis=1)
    
    return config
```

### æ¡ä»¶ç”Ÿæˆ

è®­ç»ƒæ¡ä»¶VAEï¼Œç»™å®š(T,h)ç”Ÿæˆæ„å‹ï¼š

```python
class ConditionalVAE(nn.Module):
    """æ¡ä»¶VAE"""
    
    def __init__(self, latent_dim=10, condition_dim=2):
        super().__init__()
        # å°†(T,h)æ¡ä»¶åµŒå…¥åˆ°ç¼–ç å™¨å’Œè§£ç å™¨
        ...
```

---

## ğŸ“š å‚è€ƒæ–‡çŒ®

1. **åŸè®ºæ–‡**:
   > Deep learning on the 2-dimensional Ising model to extract the crossover region with a variational autoencoder

2. **ç›¸å…³å·¥ä½œ**:
   - Carrasquilla & Melko (2017): Machine learning phases of matter
   - Wetzel (2017): Unsupervised learning of phase transitions

---

## ğŸ’¡ ä½¿ç”¨å»ºè®®

### æ•°æ®é‡é€‰æ‹©

| åº”ç”¨ | æ¨èé…ç½® | è¯´æ˜ |
|-----|---------|------|
| **å¿«é€ŸåŸå‹** | L=16, n_T=20, n_h=20 | å‡ åˆ†é’Ÿç”Ÿæˆ |
| **ç ”ç©¶å®éªŒ** | L=32, n_T=40, n_h=40 | è®ºæ–‡çš„ä¸€åŠ |
| **å‘è¡¨çº§** | L=32, n_T=65, n_h=65 | å®Œæ•´è®ºæ–‡é…ç½® |
| **å¤§è§„æ¨¡** | L=64, n_T=100, n_h=100 | éœ€è¦GPU |

### æ€§èƒ½ä¼˜åŒ–

```python
# 1. ä½¿ç”¨GPUç”Ÿæˆå™¨ï¼ˆæ¨èï¼‰
generator = GPUIsingConfigGenerator(...)

# 2. å¢é‡ä¿å­˜ï¼ˆé˜²æ­¢å†…å­˜æº¢å‡ºï¼‰
generator.generate_full_dataset(
    save_every_n_fields=10  # æ¯10ä¸ªç£åœºä¿å­˜ä¸€æ¬¡
)

# 3. æ•°æ®åŠ è½½ä¼˜åŒ–
# ä½¿ç”¨HDF5çš„éƒ¨åˆ†è¯»å–
with h5py.File('ising_data.h5', 'r') as f:
    # åªåŠ è½½éœ€è¦çš„éƒ¨åˆ†
    subset = f['configs'][0:10, :, :, :, :]  # å‰10ä¸ªç£åœº
```

---

## âœ… æ£€æŸ¥æ¸…å•

ç”Ÿæˆæ•°æ®å‰ï¼š
- [ ] ç¡®è®¤GPUå¯ç”¨ï¼ˆå¦‚ä½¿ç”¨GPUç‰ˆæœ¬ï¼‰
- [ ] ç¡®è®¤æœ‰è¶³å¤Ÿç£ç›˜ç©ºé—´ï¼ˆ~1GB for æ ‡å‡†é…ç½®ï¼‰
- [ ] é€‰æ‹©åˆé€‚çš„å‚æ•°ï¼ˆL, n_T, n_h, n_configsï¼‰

è®­ç»ƒæ¨¡å‹å‰ï¼š
- [ ] æ•°æ®å·²æˆåŠŸåŠ è½½
- [ ] æ£€æŸ¥æ•°æ®è´¨é‡ï¼ˆå¯è§†åŒ–å‡ ä¸ªæ ·æœ¬ï¼‰
- [ ] æ•°æ®å½’ä¸€åŒ–/é¢„å¤„ç†
- [ ] åˆ’åˆ†è®­ç»ƒé›†/éªŒè¯é›†/æµ‹è¯•é›†

è®­ç»ƒè¿‡ç¨‹ä¸­ï¼š
- [ ] ç›‘æ§æŸå¤±æ›²çº¿
- [ ] å®šæœŸä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹
- [ ] å¯è§†åŒ–é‡æ„ç»“æœï¼ˆVAEï¼‰
- [ ] éªŒè¯æ¨¡å‹æ³›åŒ–èƒ½åŠ›

---

## ğŸ¯ å®Œæ•´å·¥ä½œæµç¤ºä¾‹

### ä»æ•°æ®ç”Ÿæˆåˆ°æ¨¡å‹è®­ç»ƒçš„å®Œæ•´æµç¨‹

```python
# ============================================================
# æ­¥éª¤1: ç”Ÿæˆæ•°æ®
# ============================================================

from gpu_config_generator import GPUIsingConfigGenerator

print("æ­¥éª¤1: ç”Ÿæˆè®­ç»ƒæ•°æ®")
print("="*70)

generator = GPUIsingConfigGenerator(
    L=32,
    T_range=(1.0, 5.0),
    h_range=(-2.0, 2.0),
    n_T=65,
    n_h=65,
    n_configs=1024
)

dataset = generator.generate_full_dataset(
    equilibration=8192,
    sampling_interval=8,
    save_path='ising_training_data.h5'
)

print("âœ“ æ•°æ®ç”Ÿæˆå®Œæˆ\n")


# ============================================================
# æ­¥éª¤2: æ•°æ®å¯è§†åŒ–éªŒè¯
# ============================================================

print("æ­¥éª¤2: éªŒè¯æ•°æ®è´¨é‡")
print("="*70)

import matplotlib.pyplot as plt
from ising_config_saver import load_configs_hdf5

dataset = load_configs_hdf5('ising_training_data.h5')

# å¯è§†åŒ–æ ·æœ¬
fig, axes = plt.subplots(2, 4, figsize=(12, 6))
for i, ax in enumerate(axes.ravel()):
    h_idx = np.random.randint(0, 65)
    t_idx = np.random.randint(0, 65)
    config = dataset['configs'][h_idx, t_idx, 0]
    
    ax.imshow(config, cmap='gray')
    ax.set_title(f"T={dataset['temperatures'][t_idx]:.2f}, "
                f"h={dataset['fields'][h_idx]:.2f}")
    ax.axis('off')

plt.tight_layout()
plt.savefig('data_samples.png', dpi=150)
print("âœ“ æ ·æœ¬å¯è§†åŒ–å·²ä¿å­˜: data_samples.png\n")


# ============================================================
# æ­¥éª¤3: å‡†å¤‡PyTorchæ•°æ®åŠ è½½å™¨
# ============================================================

print("æ­¥éª¤3: å‡†å¤‡è®­ç»ƒæ•°æ®")
print("="*70)

import torch
from torch.utils.data import Dataset, DataLoader, random_split

class IsingDataset(Dataset):
    def __init__(self, hdf5_path):
        with h5py.File(hdf5_path, 'r') as f:
            configs = f['configs'][:]
            self.configs = configs.reshape(-1, 1, 32, 32)  # (N, 1, L, L)
            
            # å½’ä¸€åŒ–åˆ°[0, 1]
            self.configs = (self.configs + 1) / 2.0
            
            # åˆ›å»ºæ ‡ç­¾
            temps = f['temperatures'][:]
            fields = f['fields'][:]
            labels = []
            for h in fields:
                for T in temps:
                    labels.extend([(T, h)] * configs.shape[2])
            self.labels = np.array(labels)
    
    def __len__(self):
        return len(self.configs)
    
    def __getitem__(self, idx):
        return (torch.FloatTensor(self.configs[idx]), 
                torch.FloatTensor(self.labels[idx]))

# åŠ è½½æ•°æ®é›†
full_dataset = IsingDataset('ising_training_data.h5')

# åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
train_size = int(0.8 * len(full_dataset))
val_size = len(full_dataset) - train_size
train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])

train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)
val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)

print(f"è®­ç»ƒé›†å¤§å°: {train_size}")
print(f"éªŒè¯é›†å¤§å°: {val_size}")
print("âœ“ æ•°æ®åŠ è½½å™¨å‡†å¤‡å®Œæˆ\n")


# ============================================================
# æ­¥éª¤4: å®šä¹‰å¹¶è®­ç»ƒVAEæ¨¡å‹
# ============================================================

print("æ­¥éª¤4: è®­ç»ƒVAEæ¨¡å‹")
print("="*70)

class IsingVAE(nn.Module):
    def __init__(self, latent_dim=10):
        super().__init__()
        
        # ç¼–ç å™¨
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 32, 4, 2, 1),
            nn.ReLU(),
            nn.Conv2d(32, 64, 4, 2, 1),
            nn.ReLU(),
            nn.Conv2d(64, 128, 4, 2, 1),
            nn.ReLU(),
            nn.Flatten()
        )
        
        self.fc_mu = nn.Linear(128 * 4 * 4, latent_dim)
        self.fc_logvar = nn.Linear(128 * 4 * 4, latent_dim)
        
        # è§£ç å™¨
        self.fc_decode = nn.Linear(latent_dim, 128 * 4 * 4)
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(128, 64, 4, 2, 1),
            nn.ReLU(),
            nn.ConvTranspose2d(64, 32, 4, 2, 1),
            nn.ReLU(),
            nn.ConvTranspose2d(32, 1, 4, 2, 1),
            nn.Sigmoid()
        )
    
    def encode(self, x):
        h = self.encoder(x)
        return self.fc_mu(h), self.fc_logvar(h)
    
    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std
    
    def decode(self, z):
        h = self.fc_decode(z).view(-1, 128, 4, 4)
        return self.decoder(h)
    
    def forward(self, x):
        mu, logvar = self.encode(x)
        z = self.reparameterize(mu, logvar)
        return self.decode(z), mu, logvar

def vae_loss(recon_x, x, mu, logvar):
    BCE = nn.functional.binary_cross_entropy(recon_x, x, reduction='sum')
    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
    return BCE + KLD

# åˆå§‹åŒ–æ¨¡å‹
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = IsingVAE(latent_dim=10).to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

# è®­ç»ƒå¾ªç¯
num_epochs = 50
best_val_loss = float('inf')

for epoch in range(num_epochs):
    # è®­ç»ƒ
    model.train()
    train_loss = 0
    for batch_idx, (data, _) in enumerate(train_loader):
        data = data.to(device)
        
        optimizer.zero_grad()
        recon, mu, logvar = model(data)
        loss = vae_loss(recon, data, mu, logvar)
        loss.backward()
        
        train_loss += loss.item()
        optimizer.step()
    
    # éªŒè¯
    model.eval()
    val_loss = 0
    with torch.no_grad():
        for data, _ in val_loader:
            data = data.to(device)
            recon, mu, logvar = model(data)
            loss = vae_loss(recon, data, mu, logvar)
            val_loss += loss.item()
    
    train_loss /= len(train_loader.dataset)
    val_loss /= len(val_loader.dataset)
    
    print(f'Epoch {epoch+1}/{num_epochs}: '
          f'Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}')
    
    # ä¿å­˜æœ€ä½³æ¨¡å‹
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        torch.save(model.state_dict(), 'ising_vae_best.pth')

print("âœ“ è®­ç»ƒå®Œæˆï¼Œæœ€ä½³æ¨¡å‹å·²ä¿å­˜\n")


# ============================================================
# æ­¥éª¤5: è¯„ä¼°å’Œå¯è§†åŒ–
# ============================================================

print("æ­¥éª¤5: æ¨¡å‹è¯„ä¼°ä¸å¯è§†åŒ–")
print("="*70)

# åŠ è½½æœ€ä½³æ¨¡å‹
model.load_state_dict(torch.load('ising_vae_best.pth'))
model.eval()

# å¯è§†åŒ–é‡æ„ç»“æœ
fig, axes = plt.subplots(3, 8, figsize=(16, 6))

with torch.no_grad():
    for i in range(8):
        # è·å–æ ·æœ¬
        original, _ = val_dataset[i]
        original = original.unsqueeze(0).to(device)
        
        # é‡æ„
        recon, mu, logvar = model(original)
        
        # é‡‡æ ·æ–°æ„å‹
        z = torch.randn(1, 10).to(device)
        sampled = model.decode(z)
        
        # å¯è§†åŒ–
        axes[0, i].imshow(original.cpu().squeeze(), cmap='gray')
        axes[0, i].axis('off')
        if i == 0:
            axes[0, i].set_ylabel('åŸå§‹', fontsize=12)
        
        axes[1, i].imshow(recon.cpu().squeeze(), cmap='gray')
        axes[1, i].axis('off')
        if i == 0:
            axes[1, i].set_ylabel('é‡æ„', fontsize=12)
        
        axes[2, i].imshow(sampled.cpu().squeeze(), cmap='gray')
        axes[2, i].axis('off')
        if i == 0:
            axes[2, i].set_ylabel('é‡‡æ ·', fontsize=12)

plt.tight_layout()
plt.savefig('vae_results.png', dpi=150)
print("âœ“ ç»“æœå¯è§†åŒ–å·²ä¿å­˜: vae_results.png")

# æ½œåœ¨ç©ºé—´åˆ†æ
latent_codes = []
temperatures = []
fields = []

with torch.no_grad():
    for data, labels in val_loader:
        data = data.to(device)
        mu, _ = model.encode(data)
        latent_codes.append(mu.cpu().numpy())
        temperatures.append(labels[:, 0].numpy())
        fields.append(labels[:, 1].numpy())

latent_codes = np.concatenate(latent_codes)
temperatures = np.concatenate(temperatures)
fields = np.concatenate(fields)

# PCAé™ç»´å¯è§†åŒ–
from sklearn.decomposition import PCA
pca = PCA(n_components=2)
latent_2d = pca.fit_transform(latent_codes)

plt.figure(figsize=(10, 8))
scatter = plt.scatter(latent_2d[:, 0], latent_2d[:, 1], 
                     c=temperatures, cmap='coolwarm', alpha=0.5, s=1)
plt.colorbar(scatter, label='æ¸©åº¦ T')
plt.xlabel('ç¬¬ä¸€ä¸»æˆåˆ†')
plt.ylabel('ç¬¬äºŒä¸»æˆåˆ†')
plt.title('VAEæ½œåœ¨ç©ºé—´ï¼ˆPCAæŠ•å½±ï¼‰')
plt.savefig('latent_space.png', dpi=150)
print("âœ“ æ½œåœ¨ç©ºé—´å¯è§†åŒ–å·²ä¿å­˜: latent_space.png")

print("\n" + "="*70)
print("å®Œæ•´å·¥ä½œæµæ‰§è¡Œå®Œæˆï¼")
print("="*70)
print("\nç”Ÿæˆçš„æ–‡ä»¶:")
print("  - ising_training_data.h5  (è®­ç»ƒæ•°æ®)")
print("  - data_samples.png         (æ•°æ®æ ·æœ¬)")
print("  - ising_vae_best.pth       (æœ€ä½³æ¨¡å‹)")
print("  - vae_results.png          (é‡æ„ç»“æœ)")
print("  - latent_space.png         (æ½œåœ¨ç©ºé—´)")
```

---

## ğŸ”¬ è¿›é˜¶ç ”ç©¶æ–¹å‘

### 1. ä¸´ç•ŒåŒºåŸŸè¯†åˆ«

ä½¿ç”¨VAEçš„æ½œåœ¨ç©ºé—´è¯†åˆ«ä¸´ç•Œäº¤å‰åŒºåŸŸï¼š

```python
def detect_critical_region(latent_codes, temperatures):
    """
    åŸºäºæ½œåœ¨ç©ºé—´å¯†åº¦æ£€æµ‹ä¸´ç•ŒåŒºåŸŸ
    
    æ€è·¯: ä¸´ç•ŒåŒºåŸŸçš„æ„å‹åœ¨æ½œåœ¨ç©ºé—´ä¸­
          åº”è¯¥å½¢æˆè¿‡æ¸¡å¸¦
    """
    from sklearn.cluster import DBSCAN
    
    # èšç±»åˆ†æ
    clustering = DBSCAN(eps=0.5, min_samples=50)
    labels = clustering.fit_predict(latent_codes)
    
    # æ‰¾åˆ°è¿‡æ¸¡åŒºåŸŸï¼ˆå¤šä¸ªç°‡äº¤ç•Œå¤„ï¼‰
    # ...
    
    return critical_temps
```

### 2. ç›¸å˜ç‚¹é¢„æµ‹

è®­ç»ƒå›å½’æ¨¡å‹ç›´æ¥é¢„æµ‹ä¸´ç•Œæ¸©åº¦ï¼š

```python
class CriticalTempPredictor(nn.Module):
    """ä»æ„å‹é¢„æµ‹ä¸´ç•Œæ¸©åº¦"""
    
    def __init__(self):
        super().__init__()
        # ä½¿ç”¨é¢„è®­ç»ƒVAEçš„ç¼–ç å™¨
        self.encoder = pretrained_vae.encoder
        self.regressor = nn.Sequential(
            nn.Linear(latent_dim, 64),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(64, 1)
        )
    
    def forward(self, x):
        # å†»ç»“ç¼–ç å™¨
        with torch.no_grad():
            z = self.encoder(x)
        return self.regressor(z)
```

### 3. ç”Ÿæˆæ¨¡å‹åº”ç”¨

æ¡ä»¶ç”Ÿæˆï¼šç»™å®š(T, h)ç”Ÿæˆå¯¹åº”æ„å‹

```python
class ConditionalGenerator(nn.Module):
    """æ¡ä»¶ç”Ÿæˆå™¨"""
    
    def forward(self, z, T, h):
        # å°†Tå’Œhä½œä¸ºæ¡ä»¶è¾“å…¥
        condition = torch.cat([z, T, h], dim=1)
        return self.decoder(condition)

# ä½¿ç”¨
T_target = 2.269  # ä¸´ç•Œæ¸©åº¦
h_target = 0.0
z = torch.randn(1, latent_dim)
generated_config = generator(z, T_target, h_target)
```

---

## ğŸ“– å¸¸è§é—®é¢˜

### Q1: æ•°æ®å¤ªå¤§æ€ä¹ˆåŠï¼Ÿ

**A**: ä½¿ç”¨å¢é‡ç”Ÿæˆå’ŒåŠ è½½
```python
# ç”Ÿæˆæ—¶
generator.generate_full_dataset(save_every_n_fields=10)

# åŠ è½½æ—¶
with h5py.File('data.h5', 'r') as f:
    subset = f['configs'][0:10]  # åªåŠ è½½éƒ¨åˆ†
```

### Q2: GPUæ˜¾å­˜ä¸è¶³ï¼Ÿ

**A**: å‡å°æ‰¹é‡å¤§å°æˆ–ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
```python
# å°æ‰¹é‡ + æ¢¯åº¦ç´¯ç§¯
accumulation_steps = 4
for i, (data, _) in enumerate(train_loader):
    loss = compute_loss(data) / accumulation_steps
    loss.backward()
    
    if (i + 1) % accumulation_steps == 0:
        optimizer.step()
        optimizer.zero_grad()
```

### Q3: å¦‚ä½•éªŒè¯æ¨¡å‹å­¦åˆ°äº†ç‰©ç†ï¼Ÿ

**A**: æ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹ï¼š
1. æ½œåœ¨ç©ºé—´åº”è¯¥åœ¨Tcé™„è¿‘æœ‰æ˜æ˜¾ç»“æ„å˜åŒ–
2. é‡æ„çš„æ„å‹åº”ä¿æŒç‰©ç†ä¸€è‡´æ€§
3. ç”Ÿæˆçš„æ„å‹åº”ç¬¦åˆç»Ÿè®¡åˆ†å¸ƒ

---

## ğŸ“ æ€»ç»“

æ‚¨ç°åœ¨æ‹¥æœ‰ï¼š

âœ… **CPUæ„å‹ç”Ÿæˆå™¨** (`ising_config_saver.py`)
âœ… **GPUæ„å‹ç”Ÿæˆå™¨** (`gpu_config_generator.py`)  
âœ… **å®Œæ•´è®­ç»ƒæµç¨‹** (æœ¬æ–‡æ¡£)
âœ… **VAEç¤ºä¾‹ä»£ç **
âœ… **æ•°æ®å¯è§†åŒ–å·¥å…·**

**ä¸‹ä¸€æ­¥**:
1. ç”Ÿæˆæ•°æ®ï¼ˆæ¨èGPUç‰ˆæœ¬ï¼‰
2. è®­ç»ƒVAEæˆ–å…¶ä»–æ¨¡å‹
3. åˆ†ææ½œåœ¨ç©ºé—´
4. å‘è¡¨ç ”ç©¶æˆæœï¼

**ç¥ç ”ç©¶é¡ºåˆ©ï¼** ğŸš€ğŸ”¬âœ¨



ä¸‹é¢æ˜¯æŒ‰**ç°åœ¨çš„ä»£ç ç»“æ„**ï¼ˆ`ising_fss.*`ã€`dispatcher`ã€`gpu_algorithms`ã€`config_io` ç­‰ï¼‰é‡å†™åçš„ã€Œæ·±åº¦å­¦ä¹ è®­ç»ƒæŒ‡å—ã€ã€‚

* å»æ‰äº† `ising_config_saver` / `gpu_config_generator` è¿™ç±»æ—§åå­—ï¼›
* æ•°æ®ç”Ÿæˆéƒ¨åˆ†æ”¹æˆã€Œç”¨é¡¹ç›®è‡ªå¸¦è„šæœ¬ / `ising_fss` çš„ API å…ˆç”Ÿæˆ HDF5ã€ï¼›
* æ·±åº¦å­¦ä¹ éƒ¨åˆ†ä¿ç•™åŸæ¥çš„ VAE / åˆ†ç±»å™¨ç­‰ç¤ºä¾‹ï¼Œåªæ”¹æ•°æ®åŠ è½½æ¥å£ã€‚

ä½ å¯ä»¥æŠŠå®ƒæ”¾æˆ `docs/dl_training_guide.md` æˆ–ç±»ä¼¼æ–‡ä»¶ã€‚

---

````markdown
# ä¼Šè¾›æ¨¡å‹æ„å‹æ•°æ® - æ·±åº¦å­¦ä¹ è®­ç»ƒæŒ‡å—ï¼ˆåŸºäº ising_fssï¼‰

æœ¬æŒ‡å—ä»‹ç»å¦‚ä½•ä½¿ç”¨ `ising_fss` é¡¹ç›®ç”Ÿæˆçš„ä¼Šè¾›æ¨¡å‹æ„å‹æ•°æ®ï¼Œè¿›è¡Œæ·±åº¦å­¦ä¹ è®­ç»ƒï¼ˆVAEã€åˆ†ç±»å™¨ã€æ¸©åº¦å›å½’ç­‰ï¼‰ã€‚

- ä¸å…³å¿ƒæ•°æ®å¦‚ä½•äº§ç”Ÿï¼Œåªè¦æœ‰ä¸€ä¸ª HDF5 æ–‡ä»¶ï¼ˆæˆ–ç­‰ä»·çš„ NumPy æ•°ç»„ï¼‰å°±å¯ä»¥è·Ÿç€æœ¬æŒ‡å—èµ°ã€‚
- æ•°æ®ç”Ÿæˆçš„ç»†èŠ‚ä¸æ¥å£ï¼Œè§ `docs/config_data_summary.md` å’Œ `ising_fss.data.config_io`ã€‚

---

## ğŸ“Š æ•°æ®é›†æ¦‚è¿°

### å…¸å‹æ•°æ®ç»“æ„

`ising_fss.data.config_io` è¯»å‡ºçš„æ•°æ®ï¼Œæ¨èç»„ç»‡ä¸ºå¦‚ä¸‹ç»“æ„ï¼ˆä»¥ HDF5 ä¸ºä¾‹ï¼‰ï¼š

```python
dataset = {
    'configs':        # æ„å‹æ•°æ®
        # å»ºè®®å½¢çŠ¶ä¸º (n_h, n_T, n_configs, L, L)
        np.ndarray,
    'energy':         # å¯¹åº”æ„å‹çš„èƒ½é‡ï¼ˆå¯é€‰ï¼‰
        # å½¢çŠ¶ (n_h, n_T, n_configs)
        np.ndarray,
    'magnetization':  # å¯¹åº”æ„å‹çš„ç£åŒ–ï¼ˆå¯é€‰ï¼‰
        # å½¢çŠ¶ (n_h, n_T, n_configs)
        np.ndarray,
    'temperatures':   # æ¸©åº¦ç½‘æ ¼
        # å½¢çŠ¶ (n_T,)
        np.ndarray,
    'fields':         # å¤–åœºç½‘æ ¼
        # å½¢çŠ¶ (n_h,)
        np.ndarray,
    'parameters':     # å…ƒæ•°æ®ï¼ˆLã€equilibrationã€intervalã€åç«¯ã€ç®—æ³•åã€éšæœºç§å­ç­‰ï¼‰
        dict,
}
````

> å®é™…å­—æ®µåè¯·ä»¥ `config_io.py` ä¸­çš„å®ç°ä¸ºå‡†ï¼›å¦‚æœ‰å·®å¼‚ï¼Œåªè¦èƒ½æ‹¿åˆ°ç±»ä¼¼ç»“æ„å³å¯å¹³ç§»æœ¬æŒ‡å—çš„ä»£ç ã€‚

### è®ºæ–‡æ ‡å‡†é…ç½®ï¼ˆå»ºè®®ï¼‰

| å‚æ•°        | å€¼             | è¯´æ˜             |
| --------- | ------------- | -------------- |
| L         | 32            | æ™¶æ ¼å°ºå¯¸           |
| n_T       | 65            | æ¸©åº¦ç‚¹æ•°           |
| n_h       | 65            | ç£åœºç‚¹æ•°           |
| n_configs | 1024          | æ¯ä¸ª (T, h) çš„æ„å‹æ•° |
| **æ€»æ„å‹æ•°**  | **4,321,280** | 65Ã—65Ã—1024     |

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¬¬ 0 æ­¥ï¼šå‡†å¤‡ä¸€ä¸ª HDF5 æ•°æ®æ–‡ä»¶

å…¸å‹æµç¨‹æ˜¯ï¼š

1. ä½¿ç”¨ `ising_fss.simulation`ï¼ˆCPU æˆ– GPU REMCï¼‰ç”Ÿæˆæ„å‹ï¼›
2. ç”¨ `ising_fss.data.config_io.save_configs_hdf5(...)` å†™å…¥ `ising_data.h5`ï¼›
3. æœ¬æŒ‡å—åªå…³å¿ƒã€Œå¦‚ä½•ä» `ising_data.h5` è®­ç»ƒæ¨¡å‹ã€ã€‚

å‡è®¾ä½ å·²ç»æœ‰äº†ï¼š

```bash
ising_data.h5
```

å¦‚æœè¿˜æ²¡æœ‰ï¼Œå¯å‚è€ƒé¡¹ç›®ä¸­çš„ `examples/generate_dl_data.py` æˆ– `docs/config_data_summary.md`ã€‚

---

### 1. åŠ è½½æ•°æ®

æœ€ç®€å•çš„æ–¹å¼æ˜¯ç›´æ¥ç”¨ `h5py` è¯»ï¼Œç„¶ååœ¨ PyTorch Dataset é‡Œ reshapeï¼š

```python
import h5py
import numpy as np

with h5py.File('ising_data.h5', 'r') as f:
    configs = f['configs'][:]        # (n_h, n_T, n_configs, L, L)
    temps   = f['temperatures'][:]   # (n_T,)
    fields  = f['fields'][:]         # (n_h,)

print("æ„å‹å½¢çŠ¶:", configs.shape)
print("æ¸©åº¦èŒƒå›´:", temps[0], "â†’", temps[-1])
print("ç£åœºèŒƒå›´:", fields[0], "â†’", fields[-1])
```

å¦‚æœä½ æ›´æ„¿æ„èµ°é¡¹ç›®å°è£…ï¼Œä¹Ÿå¯ä»¥ï¼š

```python
from ising_fss.data import config_io

dataset = config_io.load_configs_hdf5('ising_data.h5')
configs = dataset['configs']
temps   = dataset['temperatures']
fields  = dataset['fields']
```

ä¸‹é¢æ‰€æœ‰æ·±åº¦å­¦ä¹ ä»£ç éƒ½åªä¾èµ– `configs / temperatures / fields` è¿™å‡ ä¸ªæ•°ç»„ã€‚

---

## ğŸ§  æ·±åº¦å­¦ä¹ åº”ç”¨

### ç»Ÿä¸€çš„ PyTorch Dataset å°è£…

æˆ‘ä»¬å…ˆå†™ä¸€ä¸ªé€šç”¨çš„ `IsingDataset`ï¼Œåé¢ VAE / åˆ†ç±»å™¨ / å›å½’éƒ½å¯ä»¥å…±ç”¨ï¼š

```python
import h5py
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader

class IsingDataset(Dataset):
    """ä¼Šè¾›æ„å‹æ•°æ®é›†ï¼ˆPyTorch ç‰ˆï¼‰"""
    
    def __init__(self, hdf5_path, normalize: bool = True):
        with h5py.File(hdf5_path, 'r') as f:
            # configs: (n_h, n_T, n_configs, L, L)
            configs = f['configs'][:]
            self.L = configs.shape[-1]
            
            # å±•å¹³ä¸º (N, L, L)
            self.configs = configs.reshape(-1, self.L, self.L)
            
            # æ¸©åº¦å’Œç£åœºæ ‡ç­¾
            temps = f['temperatures'][:]   # (n_T,)
            fields = f['fields'][:]        # (n_h,)
            n_h, n_T, n_cfg = configs.shape[:3]

            labels = []
            for ih, h in enumerate(fields):
                for it, T in enumerate(temps):
                    labels.extend([(float(T), float(h))] * n_cfg)
            self.labels = np.array(labels, dtype=np.float32)
        
        # å½’ä¸€åŒ–ï¼šè‡ªæ—‹ -1/+1 â†’ [0,1]ï¼Œä¾¿äºç”¨ Sigmoid/BCE
        if normalize:
            self.configs = (self.configs + 1.0) / 2.0
        
        print(f"åŠ è½½ {len(self.configs)} ä¸ªæ„å‹ï¼ŒL={self.L}")
    
    def __len__(self) -> int:
        return self.configs.shape[0]
    
    def __getitem__(self, idx):
        config = torch.from_numpy(self.configs[idx]).float().unsqueeze(0)  # (1, L, L)
        label  = torch.from_numpy(self.labels[idx])  # (2,) -> (T, h)
        return config, label

# åˆ›å»º DataLoader
dataset = IsingDataset('ising_data.h5')
train_loader = DataLoader(dataset, batch_size=128, shuffle=True, num_workers=4)
```

---

### åº”ç”¨ 1ï¼šå˜åˆ†è‡ªç¼–ç å™¨ (VAE)

#### æ¨¡å‹å®šä¹‰

```python
import torch
import torch.nn as nn

class IsingVAE(nn.Module):
    """ç®€å•çš„å·ç§¯ VAEï¼Œç”¨äº 32Ã—32 æ„å‹"""
    
    def __init__(self, L=32, latent_dim=10):
        super().__init__()
        self.L = L
        
        # ç¼–ç å™¨: (1, L, L) -> latent_dim
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 32, 4, 2, 1),  # -> (32, L/2,   L/2  )
            nn.ReLU(),
            nn.Conv2d(32, 64, 4, 2, 1), # -> (64, L/4,   L/4  )
            nn.ReLU(),
            nn.Conv2d(64, 128, 4, 2, 1),# -> (128, L/8,  L/8  )
            nn.ReLU(),
            nn.Flatten(),
        )
        
        # æ ¹æ® L æ¨ç®—å±•å¹³åçš„ç»´åº¦
        with torch.no_grad():
            dummy = torch.zeros(1, 1, L, L)
            enc_dim = self.encoder(dummy).shape[1]
        
        self.fc_mu     = nn.Linear(enc_dim, latent_dim)
        self.fc_logvar = nn.Linear(enc_dim, latent_dim)
        
        # è§£ç å™¨: latent_dim -> (1, L, L)
        self.fc_decode = nn.Linear(latent_dim, enc_dim)
        self.dec_head  = nn.Sequential(
            nn.ConvTranspose2d(128, 64, 4, 2, 1),
            nn.ReLU(),
            nn.ConvTranspose2d(64, 32, 4, 2, 1),
            nn.ReLU(),
            nn.ConvTranspose2d(32, 1, 4, 2, 1),
            nn.Sigmoid(),   # è¾“å‡º âˆˆ [0,1]
        )
    
    def encode(self, x):
        h = self.encoder(x)
        mu = self.fc_mu(h)
        logvar = self.fc_logvar(h)
        return mu, logvar
    
    @staticmethod
    def reparameterize(mu, logvar):
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std
    
    def decode(self, z):
        h = self.fc_decode(z)
        # è¿˜åŸæˆ (B, 128, L/8, L/8)
        B = z.shape[0]
        side = int((self.L // 8))
        h = h.view(B, 128, side, side)
        return self.dec_head(h)
    
    def forward(self, x):
        mu, logvar = self.encode(x)
        z   = self.reparameterize(mu, logvar)
        rec = self.decode(z)
        return rec, mu, logvar

def vae_loss(recon_x, x, mu, logvar):
    # é‡æ„æŸå¤±ï¼šäºŒå€¼äº¤å‰ç†µ
    BCE = nn.functional.binary_cross_entropy(recon_x, x, reduction='sum')
    # KL æ•£åº¦
    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
    return BCE + KLD
```

#### è®­ç»ƒå¾ªç¯

```python
from torch.utils.data import random_split, DataLoader

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

full_dataset = IsingDataset('ising_data.h5')
L = full_dataset.L

# è®­ç»ƒ/éªŒè¯åˆ’åˆ†
train_len = int(0.8 * len(full_dataset))
val_len   = len(full_dataset) - train_len
train_dataset, val_dataset = random_split(full_dataset, [train_len, val_len])

train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)
val_loader   = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)

# åˆå§‹åŒ–æ¨¡å‹
model = IsingVAE(L=L, latent_dim=10).to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

best_val = float('inf')
for epoch in range(1, 51):
    # ------------- è®­ç»ƒ -------------
    model.train()
    train_loss = 0.0
    for x, _ in train_loader:
        x = x.to(device)
        optimizer.zero_grad()
        recon, mu, logvar = model(x)
        loss = vae_loss(recon, x, mu, logvar)
        loss.backward()
        optimizer.step()
        train_loss += loss.item()
    
    train_loss /= len(train_loader.dataset)
    
    # ------------- éªŒè¯ -------------
    model.eval()
    val_loss = 0.0
    with torch.no_grad():
        for x, _ in val_loader:
            x = x.to(device)
            recon, mu, logvar = model(x)
            loss = vae_loss(recon, x, mu, logvar)
            val_loss += loss.item()
    val_loss /= len(val_loader.dataset)
    
    print(f"Epoch {epoch:3d} | train {train_loss:.4f} | val {val_loss:.4f}")
    
    if val_loss < best_val:
        best_val = val_loss
        torch.save(model.state_dict(), 'ising_vae_best.pth')
        print("  â†³ ä¿å­˜å½“å‰æœ€ä½³æ¨¡å‹ï¼šising_vae_best.pth")
```

---

### åº”ç”¨ 2ï¼šç›¸å˜åˆ†ç±»å™¨

æˆ‘ä»¬ç”¨æ¸©åº¦å¤§è‡´æ ‡è®°ç›¸ï¼ˆé“ç£ / ä¸´ç•Œ / é¡ºç£ï¼‰ï¼Œè®­ç»ƒä¸€ä¸ª CNN åˆ†ç±»å™¨ã€‚

```python
import torch.nn as nn
import torch

class IsingClassifier(nn.Module):
    """ç®€å•ç›¸åˆ†ç±»å™¨: è¾“å‡º 3 ä¸ªç±»åˆ«ï¼ˆä½æ¸© / ä¸´ç•Œ / é«˜æ¸©ï¼‰"""
    
    def __init__(self, num_classes=3):
        super().__init__()
        self.features = nn.Sequential(
            nn.Conv2d(1, 32, 3, 1, 1),
            nn.ReLU(),
            nn.MaxPool2d(2),   # L -> L/2
            nn.Conv2d(32, 64, 3, 1, 1),
            nn.ReLU(),
            nn.MaxPool2d(2),   # L/2 -> L/4
            nn.Conv2d(64, 128, 3, 1, 1),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d(1),  # -> (128,1,1)
        )
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(64, num_classes),
        )
    
    def forward(self, x):
        x = self.features(x)
        return self.classifier(x)
```

ç›¸æ ‡ç­¾ï¼šç”¨æ¸©åº¦ç²—ç•¥åˆ† 3 æ®µï¼ˆä½æ¸©ã€æœ‰åºï¼›ä¸­é—´ã€ä¸´ç•Œé™„è¿‘ï¼›é«˜æ¸©ã€æ— åºï¼‰ï¼š

```python
def temp_to_phase_label(T: float, Tc: float = 2.269) -> int:
    """
    è¿”å› 0/1/2:
      0: é“ç£ç›¸ (T << Tc)
      1: ä¸´ç•ŒåŒºé™„è¿‘
      2: é¡ºç£ç›¸ (T >> Tc)
    """
    if T < Tc * 0.8:
        return 0
    elif T < Tc * 1.2:
        return 1
    else:
        return 2
```

ä½ å¯ä»¥åœ¨ `Dataset` é‡Œç›´æ¥æŠŠ `T` è½¬æˆç›¸æ ‡å·ï¼Œä¹Ÿå¯ä»¥åœ¨è®­ç»ƒå¾ªç¯é‡Œ on-the-fly è½¬æ¢ã€‚

---

### åº”ç”¨ 3ï¼šæ¸©åº¦å›å½’

ä½¿ç”¨ CNN ç›´æ¥ä»æ„å‹é¢„æµ‹æ¸©åº¦ï¼š

```python
class TempPredictor(nn.Module):
    """ä»æ„å‹å›å½’é¢„æµ‹æ¸©åº¦ï¼ˆæ ‡é‡å›å½’ï¼‰"""
    
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv2d(1, 32, 5, 1, 2),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 3, 1, 1),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(64, 128, 3, 1, 1),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 1),
        )
    
    def forward(self, x):
        return self.net(x).squeeze(-1)
```

è®­ç»ƒç¤ºæ„ï¼š

```python
model = TempPredictor().to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
criterion = nn.MSELoss()

for epoch in range(1, 51):
    model.train()
    total_loss = 0.0
    for x, labels in train_loader:
        x = x.to(device)
        temps = labels[:, 0].to(device)  # åªç”¨æ¸©åº¦
        
        pred = model(x)
        loss = criterion(pred, temps)
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
    
    total_loss /= len(train_loader)
    print(f"Epoch {epoch:3d} | MSE {total_loss:.4f}")
```

---

## ğŸ“ˆ æ•°æ®ä¸ç›¸å›¾å¯è§†åŒ–

### ç»˜åˆ¶ (T, h) ç½‘æ ¼ä¸Šçš„æ ·æœ¬æ„å‹

```python
import matplotlib.pyplot as plt
import numpy as np
import h5py

def plot_configs_grid(hdf5_path, n_temps=5, n_fields=5, outfile='config_grid.png'):
    with h5py.File(hdf5_path, 'r') as f:
        configs = f['configs'][:]        # (n_h, n_T, n_cfg, L, L)
        temps   = f['temperatures'][:]   # (n_T,)
        fields  = f['fields'][:]         # (n_h,)
    
    n_h, n_T, n_cfg, L, _ = configs.shape
    
    t_indices = np.linspace(0, n_T-1, n_temps, dtype=int)
    h_indices = np.linspace(0, n_h-1, n_fields, dtype=int)
    
    fig, axes = plt.subplots(len(h_indices), len(t_indices), figsize=(1.8*n_temps, 1.8*n_fields))
    
    for i, ih in enumerate(h_indices):
        for j, it in enumerate(t_indices):
            ax = axes[i, j] if axes.ndim == 2 else axes[max(i,j)]
            config = configs[ih, it, 0]  # å–æ¯ä¸ªç‚¹çš„ç¬¬ä¸€ä¸ªæ„å‹
            ax.imshow(config, cmap='gray', vmin=-1, vmax=1)
            ax.axis('off')
            if i == 0:
                ax.set_title(f"T={temps[it]:.2f}", fontsize=8)
            if j == 0:
                ax.set_ylabel(f"h={fields[ih]:.2f}", fontsize=8)
    
    plt.tight_layout()
    fig.savefig(outfile, dpi=150)
    print("æ ·æœ¬ç½‘æ ¼å·²ä¿å­˜è‡³", outfile)

# ä½¿ç”¨
plot_configs_grid('ising_data.h5')
```

### ç®€å•ç›¸å›¾ï¼ˆå¹³å‡ç£åŒ–ï¼‰

```python
def plot_phase_diagram(hdf5_path, outfile='phase_diagram.png'):
    with h5py.File(hdf5_path, 'r') as f:
        configs = f['configs'][:]
        temps   = f['temperatures'][:]
        fields  = f['fields'][:]
    
    # å¹³å‡ç£åŒ–å¼ºåº¦ |M|
    mag = np.mean(configs, axis=(-1, -2))          # (n_h, n_T, n_cfg)
    avg_mag = np.mean(np.abs(mag), axis=2)         # (n_h, n_T)
    
    plt.figure(figsize=(7, 5))
    plt.imshow(
        avg_mag,
        extent=[temps[0], temps[-1], fields[0], fields[-1]],
        aspect='auto',
        origin='lower',
        cmap='RdBu_r',
    )
    plt.colorbar(label='å¹³å‡ç£åŒ–å¼ºåº¦ |M|')
    plt.xlabel('æ¸©åº¦ T')
    plt.ylabel('å¤–åœº h')
    plt.title('äºŒç»´ Ising æ¨¡å‹ç›¸å›¾ï¼ˆåŸºäºæ„å‹æ•°æ®ï¼‰')
    
    Tc = 2.269
    plt.axvline(Tc, color='white', linestyle='--', label=f'$T_c \\approx {Tc}$')
    plt.legend()
    
    plt.tight_layout()
    plt.savefig(outfile, dpi=150)
    print("ç›¸å›¾å·²ä¿å­˜è‡³", outfile)

# ä½¿ç”¨
plot_phase_diagram('ising_data.h5')
```

---

## ğŸ”§ é«˜çº§æŠ€å·§

### 1. æ•°æ®å¢å¼ºï¼ˆæ—‹è½¬ / ç¿»è½¬ï¼‰

```python
def augment_config(config: np.ndarray) -> np.ndarray:
    """å¯¹å•ä¸ª (L,L) æ„å‹åšç®€å•æ•°æ®å¢å¼º"""
    # éšæœºæ—‹è½¬ï¼ˆ90Â° çš„å€æ•°ï¼‰
    k = np.random.randint(0, 4)
    config = np.rot90(config, k)
    # éšæœºç¿»è½¬
    if np.random.rand() < 0.5:
        config = np.flip(config, axis=0)
    if np.random.rand() < 0.5:
        config = np.flip(config, axis=1)
    return config
```

å¯ä»¥åœ¨ `IsingDataset.__getitem__` é‡ŒåŠ ä¸€ä¸ª `augment` æ ‡å¿—ï¼Œåœ¨è¿”å›å‰åšå¢å¼ºã€‚

### 2. æ¡ä»¶ç”Ÿæˆï¼ˆConditional VAEï¼‰

ä½ å¯ä»¥æŠŠ `(T, h)` å½“æˆæ¡ä»¶ï¼Œæ‹¼è¿›ç¼–ç å™¨ / è§£ç å™¨ï¼Œä¾‹å¦‚ï¼š

```python
class ConditionalVAE(nn.Module):
    def __init__(self, L=32, latent_dim=10, cond_dim=2):
        super().__init__()
        # æ¡ä»¶å‘é‡ (T, h) å…ˆè¿‡ä¸ªå° MLPï¼Œç„¶åä¸å›¾åƒç‰¹å¾ concat
        # è¿™é‡Œåªç»™ç»“æ„æ€è·¯ï¼Œå…·ä½“å®ç°å¯å‚è€ƒ standard CVAE
        ...
```

---

## ğŸ’¡ å®è·µå»ºè®®ä¸ Checklist

### æ•°æ®è§„æ¨¡å»ºè®®

| åœºæ™¯        | æ¨èé…ç½®                 | è¯´æ˜        |
| --------- | -------------------- | --------- |
| å¿«é€ŸåŸå‹      | L=16, n_T=20, n_h=20 | å‡ åˆ†é’Ÿç”Ÿæˆ     |
| ç ”ç©¶å®éªŒ      | L=32, n_T=40, n_h=40 | è®ºæ–‡é…ç½®çš„ä¸€åŠ   |
| è®ºæ–‡çº§       | L=32, n_T=65, n_h=65 | å¯¹åº”åŸæ–‡å‚æ•°    |
| æ›´å¤§ä½“ç³» / æŒ‘æˆ˜ | L=64+ï¼Œè§†èµ„æºè€Œå®š          | å¼ºçƒˆå»ºè®®ç”¨ GPU |

### è®­ç»ƒå‰ Checklist

* [ ] å·²ç¡®è®¤ HDF5 æ•°æ®å®Œæ•´ï¼ˆ`configs` ç»´åº¦æ­£ç¡®ï¼‰ï¼›
* [ ] éšæœºå¯è§†åŒ–äº†è‹¥å¹²æ„å‹ï¼Œç¡®è®¤æ²¡æœ‰æ˜æ˜¾é”™è¯¯ï¼›
* [ ] ç¡®è®¤å½’ä¸€åŒ–æ–¹å¼ï¼ˆ-1/+1 â†’ 0/1ï¼‰ä¸ç½‘ç»œè¾“å‡ºæ¿€æ´»å‡½æ•°åŒ¹é…ï¼›
* [ ] åˆ’åˆ†äº† train/val/testï¼›
* [ ] è®¾å®šåˆç†çš„ batch_size ä¸å­¦ä¹ ç‡ï¼›

### è®­ç»ƒä¸åˆ†æ

* [ ] ç›‘æ§è®­ç»ƒ/éªŒè¯æŸå¤±æ˜¯å¦ç¨³å®šä¸‹é™ï¼›
* [ ] å¯¹æ¯”åŸå§‹æ„å‹ä¸é‡æ„æ„å‹çš„å¯è§†åŒ–ï¼›
* [ ] ç”¨æ½œåœ¨ç©ºé—´ (z) ç”»æ¸©åº¦æˆ–ç£åœºçš„é¢œè‰²å›¾ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ç‰©ç†ç»“æ„ï¼›
* [ ] å¯¹ä¸åŒç›¸ï¼ˆä½æ¸©/é«˜æ¸©ï¼‰çš„ z åšèšç±»æˆ–å¯è§†åŒ–ï¼ŒéªŒè¯æ¨¡å‹å­¦åˆ°ç›¸å˜ä¿¡æ¯ã€‚

---

## ğŸ“ æ€»ç»“

å½“å‰ `ising_fss` é¡¹ç›®ä¸ºä½ æä¾›äº†ï¼š

1. **ç¨³å®šå¯æ§çš„æ„å‹ç”Ÿæˆ**ï¼ˆCPU/GPU REMC + `dispatcher` + ä¸¥æ ¼ RNGï¼‰ï¼›
2. **æ ‡å‡†åŒ–çš„æ•°æ®æ ¼å¼**ï¼ˆé€šè¿‡ `config_io` / `data_manager` ä¿å­˜ HDF5ï¼‰ï¼›
3. **é¢å‘æ·±åº¦å­¦ä¹ çš„æ¥å£ä¸ç¤ºä¾‹**ï¼ˆæœ¬æŒ‡å— + `analysis.dl_tools`ï¼‰ã€‚

ä½ å¯ä»¥åœ¨æ­¤åŸºç¡€ä¸Šæ¢ç´¢ï¼š

* æ— ç›‘ç£ç›¸å˜è¯†åˆ«ï¼ˆVAE / è‡ªç¼–ç å™¨ / å¯¹æ¯”å­¦ä¹ ï¼‰ï¼›
* ç›‘ç£ç›¸åˆ†ç±» / ä¸´ç•ŒåŒºåŸŸè¯†åˆ«ï¼›
* æ¡ä»¶ç”Ÿæˆæ¨¡å‹ï¼ˆç»™å®š T,h ç”Ÿæˆæ„å‹ï¼‰ï¼›
* æ›´å¤æ‚çš„æ¶æ„ï¼šGNNã€Transformerã€æ‰©æ•£æ¨¡å‹ç­‰ã€‚

**ä¸€å¥è¯ï¼š**

> æ¨¡æ‹Ÿ + æ„å‹æ•°æ® + è¿™å¥—æ·±åº¦å­¦ä¹ æµæ°´çº¿ï¼Œå·²ç»è¶³ä»¥æ”¯æ’‘ä¸€æ•´ç¯‡ã€ŒAI Ã— ç»Ÿè®¡ç‰©ç†ã€çš„ç ”ç©¶å·¥ä½œã€‚ç¥ä½ ç©å¾—å¼€å¿ƒï¼Œä¹ŸæœŸå¾…ä½ åŸºäºè¿™å¥—æ¡†æ¶åšå‡ºè‡ªå·±çš„å˜ä½“å’Œåˆ›æ–°ã€‚ğŸš€

```
::contentReference[oaicite:0]{index=0}
```



è¿™ä¸ªæ–‡æ¡£åœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šéå¸¸è¯¦å®ï¼Œä½†ä¸æˆ‘ä»¬å®é™…çš„ä»£ç åº“ç»“æ„å­˜åœ¨**ä¸¥é‡åå·®**ã€‚å®ƒè™šæ„äº†å¤§é‡ç±»åå’Œæ–‡ä»¶åï¼ˆå¦‚ `IsingConfigGenerator`, `GPUIsingConfigGenerator`, `ising_config_saver.py` ç­‰ï¼‰ï¼Œå¦‚æœç›´æ¥å‘å¸ƒï¼Œä¼šè®©ç”¨æˆ·åœ¨ `ising-fss` åŒ…é‡Œæ‰¾ä¸åˆ°è¿™äº›ä¸œè¥¿è€Œæ„Ÿåˆ°å›°æƒ‘ã€‚

**æ ¸å¿ƒé—®é¢˜ï¼š**
æ–‡æ¡£ä¸­çš„ä»£ç ç¤ºä¾‹æ˜¯åŸºäºä¸€ä¸ª**å‡è®¾çš„ API** ç¼–å†™çš„ï¼Œè€Œä¸æ˜¯åŸºäºæˆ‘ä»¬å®é™…å®ç°çš„ `HybridREMCSimulator` / `batch_runner.py` / `dl_tools.py` ä½“ç³»ã€‚

æˆ‘ä¸ºä½ å‡†å¤‡äº†ä¸€ä»½**å®Œå…¨é‡å†™ä¸”ç»è¿‡ API å¯¹é½**çš„æ·±åº¦å­¦ä¹ æŒ‡å—ã€‚è¿™ä»½æ–‡æ¡£å°†æ‰‹æŠŠæ‰‹æ•™ç”¨æˆ·å¦‚ä½•ä½¿ç”¨ `ising-fss` çš„çœŸå®ç»„ä»¶å®Œæˆä»æ•°æ®ç”Ÿæˆåˆ° VAE è®­ç»ƒçš„å…¨è¿‡ç¨‹ã€‚

-----

# ğŸ“š æ·±åº¦å­¦ä¹ è®­ç»ƒæŒ‡å— (Deep Learning Guide)

æœ¬æŒ‡å—å°†å¼•å¯¼æ‚¨ä½¿ç”¨ `ising-fss` æ¡†æ¶å®Œæˆä» **æµ·é‡ Ising æ„å‹ç”Ÿæˆ** åˆ° **æ·±åº¦å­¦ä¹ æ¨¡å‹ (VAE) è®­ç»ƒ** çš„å®Œæ•´ç§‘ç ”å·¥ä½œæµã€‚

-----

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1\. æ•°æ®ç”Ÿæˆ (Production)

æˆ‘ä»¬æ¨èä½¿ç”¨ `batch_runner` åœ¨ GPU ä¸Šå¤§è§„æ¨¡ç”Ÿæˆæ•°æ®ã€‚

**ä»»åŠ¡ç›®æ ‡**ï¼šç”Ÿæˆ $L=32$ çš„æ„å‹ï¼Œè¦†ç›–ä¸´ç•ŒåŒºæ¸©åº¦ $T \in [1.6, 3.0]$ï¼Œç”¨äºè®­ç»ƒç¥ç»ç½‘ç»œã€‚

```bash
# 1. å¯åŠ¨ GPU æ¨¡æ‹Ÿ (æ¨è)
# ä½¿ç”¨ metropolis_sweep ç®—æ³•ï¼Œæ¯è¿›ç¨‹è·‘ 32 ä¸ªå‰¯æœ¬
python -m ising_fss.simulation.batch_runner \
    --mode run_workers \
    --nworkers 4 \
    --L 32 \
    --T 2.269 \
    --replicas 32 \
    --algo metropolis_sweep \
    --equil 5000 \
    --prod 20000 \
    --thin 10 \
    --save_lattices \
    --outdir ./data_dl_L32

# 2. åˆå¹¶æ•°æ®
python -m ising_fss.simulation.batch_runner \
    --mode merge \
    --outdir ./data_dl_L32
```

*äº§å‡ºæ–‡ä»¶*ï¼š`./data_dl_L32/merged/final_ml_data.h5` (åŒ…å«æ„å‹ã€æ¸©åº¦ã€ç£åœºç­‰)

### 2\. æ•°æ®æ¸…æ´—ä¸å¯¼å‡º (ETL)

åŸå§‹ HDF5 æ•°æ®å¯èƒ½éå¸¸å·¨å¤§ä¸”æœªå½’ä¸€åŒ–ã€‚æˆ‘ä»¬æä¾› `export_for_pytorch` å·¥å…·å°†å…¶è½¬æ¢ä¸º **AI-Ready** æ ¼å¼ã€‚

```python
# scripts/prepare_dl_data.py
from ising_fss.data.config_io import load_configs_hdf5, export_for_pytorch

# åŠ è½½åŸå§‹æ•°æ® (Lazy Modeï¼Œä¸å å†…å­˜)
dataset = load_configs_hdf5("./data_dl_L32/merged/final_ml_data.h5", load_configs=False)

# å¯¼å‡ºä¸º PyTorch æ ¼å¼
# - è‡ªåŠ¨å‹ç¼©ä¸º uint8
# - å½’ä¸€åŒ–åˆ° [0, 1]
# - åˆ’åˆ† 80% è®­ç»ƒé›†
export_for_pytorch(
    dataset,
    save_dir="./data_ready/L32",
    split_ratio=0.8,
    dtype='uint8',
    normalize=True,
    verbose=True
)
```

-----

## ğŸ§¬ æ•°æ®åŠ è½½ (Data Loading)

`ising-fss` æä¾›äº†é«˜æ€§èƒ½çš„ `DataLoader` å·¥å‚ï¼Œæ”¯æŒ**ç¡®å®šæ€§æ•°æ®å¢å¼º**ã€‚è¿™æ„å‘³ç€æ—‹è½¬/ç¿»è½¬æ“ä½œä¸æ ·æœ¬ç´¢å¼•ç»‘å®šï¼Œä¿è¯è®­ç»ƒè¿‡ç¨‹å®Œå…¨å¯å¤ç°ã€‚

```python
import torch
from ising_fss.analysis.dl_tools import create_dataloaders_from_path, AugmentConfig

# é…ç½®ç¡®å®šæ€§å¢å¼º (D4å¯¹ç§°ç¾¤)
aug_cfg = AugmentConfig(enable=True, rot90=True, hflip=True, vflip=True)

# ä¸€é”®åˆ›å»º Loaders
loaders = create_dataloaders_from_path(
    "./data_ready/L32",
    batch_size=128,
    num_workers=4,
    augment=aug_cfg,
    pin_memory=True
)

train_loader = loaders['train']
val_loader = loaders['val']

# æµ‹è¯•è¯»å–
batch = next(iter(train_loader))
x = batch['config']       # Tensor (B, 1, 32, 32), range [0, 1]
T = batch['temperature']  # Tensor (B,), å¯¹åº”æ¸©åº¦
```

-----

## ğŸ§  è®­ç»ƒç¤ºä¾‹ï¼šå˜åˆ†è‡ªç¼–ç å™¨ (VAE)

æˆ‘ä»¬å°†è®­ç»ƒä¸€ä¸ª VAE æ¥æ— ç›‘ç£åœ°å­¦ä¹  Ising æ¨¡å‹çš„æ½œåœ¨åºå‚é‡ï¼ˆOrder Parameterï¼‰ã€‚

### å®šä¹‰æ¨¡å‹

```python
import torch.nn as nn
import torch.nn.functional as F

class IsingVAE(nn.Module):
    def __init__(self, latent_dim=2):
        super().__init__()
        # Encoder
        self.enc = nn.Sequential(
            nn.Conv2d(1, 32, 3, 2, 1), nn.ReLU(),
            nn.Conv2d(32, 64, 3, 2, 1), nn.ReLU(),
            nn.Flatten()
        )
        self.fc_mu = nn.Linear(64*8*8, latent_dim)
        self.fc_logvar = nn.Linear(64*8*8, latent_dim)
        
        # Decoder
        self.dec_fc = nn.Linear(latent_dim, 64*8*8)
        self.dec = nn.Sequential(
            nn.Unflatten(1, (64, 8, 8)),
            nn.ConvTranspose2d(64, 32, 3, 2, 1, output_padding=1), nn.ReLU(),
            nn.ConvTranspose2d(32, 1, 3, 2, 1, output_padding=1), nn.Sigmoid()
        )

    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std

    def forward(self, x):
        h = self.enc(x)
        mu, logvar = self.fc_mu(h), self.fc_logvar(h)
        z = self.reparameterize(mu, logvar)
        return self.dec(z), mu, logvar
```

### è®­ç»ƒå¾ªç¯

```python
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = IsingVAE().to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

def loss_fn(recon_x, x, mu, logvar):
    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')
    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
    return BCE + KLD

print(f"å¼€å§‹è®­ç»ƒ on {device}...")
for epoch in range(10):
    total_loss = 0
    for batch in train_loader:
        x = batch['config'].to(device)
        optimizer.zero_grad()
        recon, mu, logvar = model(x)
        loss = loss_fn(recon, x, mu, logvar)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    
    print(f"Epoch {epoch+1}: Avg Loss = {total_loss / len(train_loader.dataset):.2f}")
```

-----

## ğŸ“Š ç»“æœå¯è§†åŒ–

### 1\. æ½œåœ¨ç©ºé—´æŠ•å½± (Latent Space)

åˆ©ç”¨ `ising-fss` å†…ç½®çš„å¯è§†åŒ–å·¥å…·ï¼Œè§‚å¯Ÿ VAE å­¦ä¹ åˆ°çš„æ½œåœ¨å˜é‡ $z$ å¦‚ä½•éšæ¸©åº¦ $T$ åˆ†å¸ƒã€‚

```python
from ising_fss.visualization.plots import plot_latent_space
import numpy as np

# æ”¶é›†éªŒè¯é›†çš„æ½œåœ¨å‘é‡
zs, temps = [], []
with torch.no_grad():
    for batch in val_loader:
        x = batch['config'].to(device)
        mu, _ = model.enc(x), None  # ç®€åŒ–ï¼šåªå– mu åçš„fcè¾“å‡ºéœ€è‡ªè¡Œè°ƒæ•´ï¼Œè¿™é‡Œå‡è®¾æ‹¿åˆ° z
        # æ³¨æ„ï¼šä¸Šé¢çš„ VAE ä»£ç éœ€è¦å¾®è°ƒä»¥ç›´æ¥è¿”å› zï¼Œæˆ–è€…æ‹†è§£ forward
        # è¿™é‡Œä»…ä½œé€»è¾‘ç¤ºæ„
        h = model.enc(x)
        z = model.fc_mu(h)
        zs.append(z.cpu().numpy())
        temps.append(batch['temperature'].numpy())

plot_latent_space(
    latent_codes=np.concatenate(zs),
    labels=np.concatenate(temps),
    label_type='temperature',
    save_path="vae_latent_space.png"
)
```

> **é¢„æœŸç»“æœ**ï¼šä½ åº”è¯¥èƒ½çœ‹åˆ°æ½œåœ¨ç©ºé—´ä¸­å‘ˆç°å‡ºæ˜æ˜¾çš„â€œå‰â€çŠ¶æˆ–â€œVâ€å­—å½¢ç»“æ„ï¼Œåˆ†åˆ«å¯¹åº”ä½æ¸©æœ‰åºç›¸ï¼ˆä¸¤ä¸ªåˆ†æ”¯å¯¹åº”è‡ªæ—‹å‘ä¸Š/å‘ä¸‹ï¼‰å’Œé«˜æ¸©æ— åºç›¸ã€‚

### 2\. é‡æ„è´¨é‡ (Reconstruction)

```python
from ising_fss.visualization.plots import plot_vae_reconstruction

# å–ä¸€ä¸ª batch
batch = next(iter(val_loader))
x = batch['config'].to(device)[:8]
with torch.no_grad():
    recon, _, _ = model(x)

plot_vae_reconstruction(
    original=x.cpu().squeeze().numpy(),
    reconstructed=recon.cpu().squeeze().numpy(),
    save_path="vae_recon_comparison.png"
)
```

-----

## ğŸ”¬ è¿›é˜¶ï¼šç‰©ç†æ„ŸçŸ¥ (Physics-Informed)

`dl_tools` æä¾›äº†è®¡ç®—ç‰©ç†é‡çš„å·¥å…·ï¼Œä½ å¯ä»¥å°†å…¶åŠ å…¥ Loss å‡½æ•°ï¼Œè¿«ä½¿æ¨¡å‹å­¦ä¹ ç‰©ç†çº¦æŸã€‚

```python
from ising_fss.analysis.dl_tools import energy_density, magnetization

# åœ¨è®­ç»ƒå¾ªç¯ä¸­ç›‘æ§ç‰©ç†é‡ä¸€è‡´æ€§
pred_E = energy_density(recon_x)
true_E = energy_density(x)
physics_loss = F.mse_loss(pred_E, true_E)

# Total Loss = VAE_Loss + lambda * physics_loss
```

-----

ç¥ä½ çš„ AI + Physics ä¹‹æ—…å……æ»¡å‘ç°ï¼ğŸš€



æ”¶åˆ°ã€‚å¦‚æœæ‚¨**ä¸éœ€è¦å½’ä¸€åŒ–**ï¼ˆå³å¸Œæœ›ä¿ç•™ç‰©ç†ä¸Šçš„è‡ªæ—‹å€¼ $\{-1, 1\}$ï¼‰ï¼Œè¿™å¯¹ç‰©ç†æ„ŸçŸ¥ï¼ˆPhysics-Informedï¼‰çš„è®­ç»ƒå…¶å®æ›´å¥½ï¼Œå› ä¸ºå¯ä»¥ç›´æ¥è®¡ç®—èƒ½é‡è€Œæ— éœ€åå½’ä¸€åŒ–ã€‚

ä½†æœ‰ä¸€ç‚¹å¿…é¡»æ³¨æ„ï¼š**å¦‚æœä¸å½’ä¸€åŒ–ï¼Œå°±ä¸èƒ½ä½¿ç”¨ `uint8` å­˜å‚¨**ï¼ˆå› ä¸º `uint8` æ˜¯æ— ç¬¦å·çš„ $0 \sim 255$ï¼Œæ— æ³•è¡¨ç¤º $-1$ï¼‰ã€‚

è¯·æŒ‰ç…§ä»¥ä¸‹æ–¹æ¡ˆè°ƒæ•´æ‚¨çš„ **æ•°æ®å¯¼å‡º** å’Œ **æ•°æ®åŠ è½½** æµç¨‹ï¼š

### 1\. ä¿®æ”¹æ•°æ®å¯¼å‡ºè„šæœ¬ (`prepare_data.py`)

åœ¨è°ƒç”¨ `export_for_pytorch` æ—¶ï¼Œåšä¸¤ä¸ªå…³é”®æ”¹åŠ¨ï¼š

1.  `normalize=False`ï¼šå…³é—­å½’ä¸€åŒ–ã€‚
2.  `dtype='float32'`ï¼š**å¿…é¡»**æ”¹ä¸ºæµ®ç‚¹æ•°ï¼ˆæˆ–ä¿®æ”¹ä»£ç æ”¯æŒ `int8`ï¼‰ã€‚å› ä¸ºé»˜è®¤çš„ `uint8` æ— æ³•å­˜å‚¨è´Ÿæ•°ã€‚

<!-- end list -->

```python
from ising_fss.data.config_io import load_configs_hdf5, export_for_pytorch

# åŠ è½½åŸå§‹æ•°æ®
dataset = load_configs_hdf5("./data_factory/raw/merged/final_ml_data.h5", load_configs=False)

# å¯¼å‡ºè®¾ç½®ï¼šä¿ç•™åŸå§‹ç‰©ç†æ•°å€¼ {-1, 1}
export_for_pytorch(
    dataset,
    save_dir="./data_ready/L32_Raw", # å»ºè®®æ¢ä¸ªç›®å½•ååŒºåˆ†
    split_ratio=0.8,
    
    # ğŸ”¥ å…³é”®ä¿®æ”¹ç‚¹ ğŸ”¥
    normalize=False,   # å…³æ‰å½’ä¸€åŒ–ï¼ä¿æŒ -1/1
    dtype='float32',   # å¿…é¡»ç”¨ float32 (å½“å‰ä»£ç ä¸æ”¯æŒ int8 å¯¼å‡ºï¼Œuint8 å­˜ä¸äº†è´Ÿæ•°)
    
    verbose=True
)
```

> **ğŸ’¡ è¿›é˜¶ä¼˜åŒ–ï¼ˆèŠ‚çœ 4 å€ç©ºé—´ï¼‰ï¼š**
> å¦‚æœæ‚¨éå¸¸åœ¨æ„ç£ç›˜ç©ºé—´ï¼Œå¸Œæœ›ç”¨ `int8` (1å­—èŠ‚) å­˜å‚¨ $\{-1, 1\}$ï¼Œæ‚¨éœ€è¦å¾®è°ƒ `src/ising_fss/data/config_io.py` æ–‡ä»¶ï¼š
>
> 1.  æ‰¾åˆ° `assert dtype in ('float32', 'uint8')`ï¼ŒåŠ å…¥ `'int8'`ã€‚
> 2.  åœ¨ä¸‹æ–¹çš„ `dtype` åˆ¤æ–­é€»è¾‘ä¸­åŠ å…¥ï¼š
>     ```python
>     elif dtype == 'int8':
>         x_out = configs_norm.astype(np.int8)
>     ```
>
> è¿™æ ·æ‚¨å°±å¯ä»¥ä½¿ç”¨ `dtype='int8'` å¯¼å‡ºäº†ã€‚

### 2\. ä¿®æ”¹æ•°æ®åŠ è½½ä»£ç  (`train.py`)

åœ¨åˆ›å»º DataLoader æ—¶ï¼ŒåŒæ ·éœ€è¦æ˜¾å¼å…³é—­å½’ä¸€åŒ–ã€‚

```python
from ising_fss.analysis.dl_tools import create_dataloaders_from_path

loaders = create_dataloaders_from_path(
    "./data_ready/L32_Raw", # æŒ‡å‘åˆšæ‰å¯¼å‡ºçš„ raw æ•°æ®ç›®å½•
    batch_size=128,
    num_workers=4,
    
    # ğŸ”¥ å…³é”®ä¿®æ”¹ç‚¹ ğŸ”¥
    normalize=False,  # å‘Šè¯‰ Loader ä¸è¦è‡ªåŠ¨æŠŠæ•°æ®ç¼©æ”¾åˆ° [0,1]
    
    pin_memory=True
)

# éªŒè¯ä¸€ä¸‹
batch = next(iter(loaders['train']))
x = batch['config']
print(f"æ•°æ®èŒƒå›´: Min={x.min()}, Max={x.max()}") 
# è¾“å‡ºåº”ä¸º: Min=-1.0, Max=1.0 (å¦‚æœæ˜¯ float32)
```

### 3\. å¯¹æ¨¡å‹çš„å½±å“

å¦‚æœä¸å½’ä¸€åŒ–ï¼Œæ‚¨çš„æ•°æ®æ˜¯ $\{-1, 1\}$ï¼š

  * **è¾“å…¥å±‚**ï¼šç¥ç»ç½‘ç»œå®Œå…¨å¯ä»¥å¤„ç†è´Ÿæ•°è¾“å…¥ï¼Œé€šå¸¸ä¸éœ€è¦æ”¹åŠ¨æ¨¡å‹ç»“æ„ã€‚
  * **æ¿€æ´»å‡½æ•°**ï¼š
      * å¦‚æœæ˜¯ **VAE**ï¼Œè¾“å‡ºå±‚ï¼ˆDecoderæœ€åä¸€å±‚ï¼‰ä»¥å‰å¯èƒ½ç”¨äº† `Sigmoid`ï¼ˆè¾“å‡º $0 \sim 1$ï¼‰ã€‚
      * **ä¿®æ”¹å»ºè®®**ï¼šç°åœ¨åº”è¯¥æ”¹ç”¨ **`Tanh`**ï¼ˆè¾“å‡º $-1 \sim 1$ï¼‰ä½œä¸ºæœ€åä¸€å±‚çš„æ¿€æ´»å‡½æ•°ï¼Œæˆ–è€…ä¸åŠ æ¿€æ´»å‡½æ•°ï¼ˆLinearï¼‰å¹¶ç»“åˆ MSE Lossã€‚

**VAE æ¨¡å‹ä¿®æ”¹ç¤ºä¾‹ï¼š**

```python
class IsingVAE(nn.Module):
    # ... (Encoder ä¸å˜) ...
    
    def __init__(self, ...):
        # ...
        self.dec = nn.Sequential(
            # ... å‰é¢çš„å±‚ä¸å˜ ...
            nn.ConvTranspose2d(...),
            
            # ğŸ”¥ ä¿®æ”¹ç‚¹ï¼šä» Sigmoid æ”¹ä¸º Tanh ğŸ”¥
            nn.Tanh()  # è¾“å‡ºèŒƒå›´ [-1, 1]
        )
```

è¿™æ ·æ‚¨çš„æ•´ä¸ªç®¡çº¿å°±å®Œå…¨åŸºäºç‰©ç†åŸå§‹æ•°å€¼è¿è¡Œäº†ã€‚