# examples/cpu_remc_large_scale_fss.py
"""
åŸºäº CPU / HybridREMCSimulator çš„ REMC â†’ FSS ç®¡çº¿è„šæœ¬ã€‚

ç›®æ ‡ï¼š
- è¡Œä¸ºå°½é‡æ¨¡ä»¿ gpu_large_scale_fss.pyï¼ˆ42_gpu_large_scale_fss.pyï¼‰ï¼š
  * æ”¯æŒå¤šæ¬¡è¿è¡ŒåŒä¸€ä¸ª outdirï¼Œè‡ªåŠ¨åœ¨ raw_results.json é‡Œâ€œè¿½åŠ æ ·æœ¬â€ï¼›
  * æ¯æ¬¡ run ä¹‹åéƒ½ç”¨ FSSAnalyzer åšä¸€æ¬¡ Tc / Î³/Î½ / æ•°æ®å¡Œç¼©åˆ†æï¼›
  * æŠŠ Binder U çš„ crossing ä¿¡æ¯å†™å…¥ Tc_est.jsonã€‚
- åŒºåˆ«ï¼š
  * è¿™é‡Œç”¨çš„æ˜¯ HybridREMCSimulatorï¼ˆCPU / æ··åˆå®ç°ï¼‰ï¼Œè€Œä¸æ˜¯ GPU ç‰ˆæ¨¡æ‹Ÿå™¨ï¼›
  * æš‚ä¸åš checkpoint æ¢å¤ï¼ˆå¯ä»¥ä»¥åå†æŒ‰ remc_simulator çš„æ¥å£åŠ ä¸Šï¼‰ã€‚
"""

from __future__ import annotations

import sys
import json
import math
from pathlib import Path
from typing import Dict, Any

import numpy as np

# CuPy æ˜¯å¯é€‰çš„ï¼šæ²¡æœ‰ GPU ä¹Ÿä¸ä¼šå½±å“ CPU ç‰ˆè„šæœ¬
try:
    import cupy as cp  # type: ignore
    from cupy import ndarray as cupy_ndarray  # type: ignore
except Exception:
    cp = None
    cupy_ndarray = None

# ---------- sys.path è®¾ç½® ----------
ROOT = Path(__file__).resolve().parents[1]
for p in (ROOT, ROOT / "src"):
    s = str(p)
    if s not in sys.path:
        sys.path.insert(0, s)

from ising_fss.simulation.remc_simulator import HybridREMCSimulator
from ising_fss.simulation.dispatcher import make_replica_seeds
from ising_fss.analysis.fss_analyzer import FSSAnalyzer


# ---------- json.dump helper ----------
def json_default(o):
    """
    è®© json.dump èƒ½å¤„ç† numpy / cupy / set ç­‰ç±»å‹ï¼š
      - numpy æ ‡é‡ â†’ Python æ ‡é‡
      - numpy / cupy æ•°ç»„ â†’ list
      - å…¶å®ƒä¸è®¤è¯†çš„ â†’ repr(o)
    """
    # numpy æ ‡é‡
    if isinstance(o, (np.floating, np.integer)):
        return o.item()

    # numpy æ•°ç»„
    if isinstance(o, np.ndarray):
        return o.tolist()

    # cupy æ•°ç»„
    if cp is not None and cupy_ndarray is not None:
        if isinstance(o, cupy_ndarray):  # type: ignore[attr-defined]
            try:
                return cp.asnumpy(o).tolist()  # type: ignore[attr-defined]
            except Exception:
                return repr(o)

    # 0-d array / å…¶å®ƒâ€œæœ‰ item() çš„æ ‡é‡â€
    if hasattr(o, "shape") and getattr(o, "shape", None) == () and hasattr(o, "item"):
        try:
            return o.item()
        except Exception:
            pass

    # set â†’ list
    if isinstance(o, set):
        return list(o)

    # å…œåº•ï¼šå­—ç¬¦ä¸²è¡¨ç¤º
    return repr(o)


# ---------- åŸå§‹ analyze() â†’ FSSAnalyzer è¾“å…¥æ ¼å¼ ----------

def to_fss_format(res_raw: Dict[str, Any]) -> Dict[float, Dict[str, Any]]:
    """
    å°† REMC æ¨¡æ‹Ÿå™¨çš„åŸå§‹ analyze() è¾“å‡ºè½¬æ¢ä¸º FSSAnalyzer éœ€è¦çš„æ ¼å¼ï¼š

        è¾“å…¥ï¼šres_raw = {
            "T_2.100000": {...},
            "T_2.225664": {...},
            "swap": {...},
            "field": 0.0,
            ...
        }

        è¾“å‡ºï¼š{
            2.100000: {...},
            2.225664: {...},
            ...
        }

    åªä¿ç•™ key å½¢å¦‚ "T_..." ä¸” value ä¸º dict çš„æ¡ç›®ã€‚
    å¹¶ä¸”åœ¨è¿™é‡Œå°½é‡æŠŠæ ‡é‡ / æ•°ç»„éƒ½è½¬æˆ float64ï¼Œé¿å…ç²¾åº¦é€€åŒ–ã€‚
    """
    out: Dict[float, Dict[str, Any]] = {}

    for key, val in res_raw.items():
        if not (isinstance(key, str) and key.startswith("T_") and isinstance(val, dict)):
            continue
        try:
            T = float(key.split("_", 1)[1])
        except Exception:
            continue

        obs: Dict[str, Any] = {}
        for k, x in val.items():
            # æ ‡é‡ç±»ï¼šè½¬æˆ numpy.float64ï¼ˆæˆ– Python float ä¹Ÿç­‰ä»·äºåŒç²¾åº¦ï¼‰
            if isinstance(x, (int, float, np.floating)):
                obs[k] = np.float64(x)
            # numpy æ•°ç»„ï¼šè½¬æˆ float64 æ•°ç»„
            elif isinstance(x, np.ndarray):
                obs[k] = np.asarray(x, dtype=np.float64)
            # cupy æ•°ç»„ï¼šå…ˆæ¬åˆ° hostï¼Œå†è½¬ float64
            elif cp is not None and cupy_ndarray is not None and isinstance(x, cupy_ndarray):  # type: ignore[attr-defined]
                obs[k] = cp.asnumpy(x).astype(np.float64)  # type: ignore[attr-defined]
            else:
                # å…¶å®ƒç±»å‹ï¼ˆæ¯”å¦‚å­—ç¬¦ä¸²ã€æ•´æ•°åˆ—è¡¨ã€å…ƒç»„ï¼‰åŸæ ·ä¿ç•™
                obs[k] = x

        out[np.float64(T)] = obs

    return out


# ---------- åˆå¹¶å¤šæ¬¡ runï¼šold + new ----------

def merge_analyze_for_one_L(
    old_L: Dict[str, Any],
    new_L: Dict[str, Any],
    L: int,
) -> Dict[str, Any]:
    """
    æŠŠåŒä¸€ä¸ª Lï¼ˆä¾‹å¦‚ L=128ï¼‰åœ¨å¤šæ¬¡ run ä¸­å¾—åˆ°çš„ analyze() ç»“æœåˆå¹¶ï¼š

    - å¯¹æ¯ä¸ªæ¸©åº¦å— "T_xxx"ï¼š
        * old å’Œ new ä¸­çš„ E_samples / M_samples æ‹¼æ¥ï¼ˆä»¥ float64 å­˜å‚¨ï¼‰ï¼›
        * ç”¨æ‹¼æ¥åçš„åºåˆ—é‡æ–°è®¡ç®—ï¼šE, M, C, chi, U, n_samples ç­‰ï¼›
        * E_err, M_err ç”¨ç®€å• sqrt(var/N) å…œåº•ï¼ˆä¸åš bootstrapï¼‰ï¼Œ
          è¿™æ ·ä¸ GPU ç‰ˆ analyze() çš„é€»è¾‘ä¿æŒä¸€è‡´çš„é‡çº²ï¼›
    - å¯¹ swapï¼š
        * è‹¥ attempts / accepts ç»´åº¦ä¸€è‡´ï¼Œåˆ™ç›´æ¥é€å¯¹ç›¸åŠ ï¼›
        * å¦åˆ™ä¿ç•™ new_L["swap"]ã€‚
    - å¯¹å…¶å®ƒé”®ï¼ˆfieldã€rng_versions ç­‰ï¼‰ï¼š
        * ä¼˜å…ˆä½¿ç”¨ new_L ä¸­çš„æ¡ç›®ï¼›
        * old_L ä¸­æœ‰è€Œ new_L ä¸­æ²¡æœ‰çš„é”®ä¼šè¢«ä¿ç•™ã€‚
    """
    N_site = int(L) * int(L)
    merged: Dict[str, Any] = {}

    # å…ˆéå†â€œæ–°ç»“æœâ€ï¼Œé€ä¸ª key åˆå¹¶
    for key, new_block in new_L.items():
        # --- æ¸©åº¦å— T_xxx ---
        if isinstance(key, str) and key.startswith("T_") and isinstance(new_block, dict):
            old_block = old_L.get(key, {})

            # æ˜ç¡®ç”¨ float64
            e_old = np.asarray(old_block.get("E_samples", []), dtype=np.float64)
            e_new = np.asarray(new_block.get("E_samples", []), dtype=np.float64)
            m_old = np.asarray(old_block.get("M_samples", []), dtype=np.float64)
            m_new = np.asarray(new_block.get("M_samples", []), dtype=np.float64)

            if e_old.size or e_new.size:
                if e_old.size and e_new.size:
                    e_all = np.concatenate([e_old, e_new])
                else:
                    e_all = e_old if e_old.size else e_new
            else:
                e_all = np.asarray([], dtype=np.float64)

            if m_old.size or m_new.size:
                if m_old.size and m_new.size:
                    m_all = np.concatenate([m_old, m_new])
                else:
                    m_all = m_old if m_old.size else m_new
            else:
                m_all = np.asarray([], dtype=np.float64)

            if e_all.size == 0:
                # æ²¡æœ‰æ ·æœ¬ï¼Œå°±ç›´æ¥ä½¿ç”¨ new_block
                merged[key] = new_block
                continue

            # æ¸©åº¦ T çš„ç¡®å®šä¼˜å…ˆçº§ï¼šnew_block["T"] > old_block["T"] > ä» key è§£æ
            T_val_raw = None
            if isinstance(new_block.get("T", None), (int, float, np.floating)):
                T_val_raw = float(new_block["T"])
            elif isinstance(old_block.get("T", None), (int, float, np.floating)):
                T_val_raw = float(old_block["T"])
            if T_val_raw is None:
                T_val_raw = float(key.split("_", 1)[1])

            T_val = np.float64(T_val_raw)
            beta = np.float64(1.0) / T_val

            mean_e = np.float64(np.mean(e_all))
            if m_all.size:
                mean_m = np.float64(np.mean(m_all))
            else:
                mean_m = np.float64(0.0)

            m2 = m_all ** 2 if m_all.size else np.asarray([], dtype=np.float64)
            m4 = m_all ** 4 if m_all.size else np.asarray([], dtype=np.float64)
            mean_m2 = np.float64(np.mean(m2)) if m2.size else np.float64(0.0)

            var_e = max(np.float64(0.0), np.float64(np.mean(e_all ** 2) - mean_e ** 2))
            if m_all.size:
                var_m = max(np.float64(0.0), mean_m2 - mean_m ** 2)
            else:
                var_m = np.float64(0.0)

            C_point = (beta ** 2) * np.float64(N_site) * var_e
            chi_point = beta * np.float64(N_site) * var_m

            if mean_m2 <= np.float64(1e-15):
                U = np.float64(0.0)
            else:
                m4_mean = np.float64(np.mean(m4)) if m4.size else np.float64(0.0)
                U = np.float64(1.0) - m4_mean / (np.float64(3.0) * (mean_m2 ** 2 + np.float64(1e-16)))

            N_samples = int(e_all.size)
            E_err = np.float64(math.sqrt(float(var_e) / max(1, N_samples)))
            if m_all.size:
                M_err = np.float64(math.sqrt(float(var_m) / max(1, N_samples)))
            else:
                M_err = np.float64(0.0)

            merged[key] = {
                "T": float(T_val),
                "E": float(mean_e),
                "E_err": float(E_err),
                "M": float(mean_m),
                "M_err": float(M_err),
                "C": float(C_point),
                "C_err": 0.0,   # å¦‚éœ€ bootstrapï¼Œå¯åœ¨åå¤„ç†é˜¶æ®µåš
                "chi": float(chi_point),
                "chi_err": 0.0,
                "U": float(U),
                "n_samples": int(N_samples),
                "E_samples": e_all,  # è¿™é‡Œä¿ç•™ä¸º float64 æ•°ç»„
                "M_samples": m_all,
            }

        # --- swap ç»Ÿè®¡ ---
        elif key == "swap" and isinstance(new_block, dict):
            old_block = old_L.get("swap", {})
            a_old = np.asarray(old_block.get("attempts", []), dtype=np.int64)
            a_new = np.asarray(new_block.get("attempts", []), dtype=np.int64)
            c_old = np.asarray(old_block.get("accepts", []), dtype=np.int64)
            c_new = np.asarray(new_block.get("accepts", []), dtype=np.int64)

            if a_old.size and a_new.size and a_old.size == a_new.size:
                a_all = (a_old + a_new)
                if c_old.size and c_old.size == c_new.size:
                    c_all = (c_old + c_new)
                else:
                    c_all = c_new
                merged[key] = {
                    "attempts": a_all,
                    "accepts": c_all,
                    "total_attempts": int(np.sum(a_all)),
                    "total_accepts": int(np.sum(c_all)),
                }
            else:
                merged[key] = new_block

        # --- å…¶å®ƒé”®ï¼šä¼˜å…ˆ newï¼Œå…¶æ¬¡ old ---
        else:
            if key in old_L and key not in merged:
                # old é‡Œæœ‰ã€new é‡Œæ²¡æœ‰çš„é”®ï¼Œå…ˆæ”¾ old
                merged[key] = old_L[key]
            # new ä¸­çš„å€¼è¦†ç›– old
            merged[key] = new_block

    # å†æŠŠ old_L é‡Œé—æ¼çš„é”®è¡¥ä¸Š
    for key, old_block in old_L.items():
        if key not in merged:
            merged[key] = old_block

    return merged


# ---------- CPU ç‰ˆï¼šè·‘å•ä¸ª L çš„ REMC ----------

def run_one_L(L: int, outdir: Path, args) -> Dict[str, Any]:
    """
    è·‘å•ä¸ª L çš„ HybridREMCSimulator REMCï¼Œè¿”å› sim.analyze() çš„åŸå§‹ç»“æœï¼š
        {
          "T_2.100000": {...},
          "T_2.225664": {...},
          "swap": {...},
          "field": 0.0,
          ...
        }
    """
    T_min = float(args.T_min)
    T_max = float(args.T_max)
    num_replicas = int(args.num_replicas)

    replica_seeds = make_replica_seeds(master_seed=10_000 + int(L), n_replicas=num_replicas)

    print(
        f"\n=== è¿è¡Œ REMC (CPU ç‰ˆ): L={L}, "
        f"Tâˆˆ[{T_min}, {T_max}], replicas={num_replicas}, algo=metropolis_sweep ==="
    )

    sim = HybridREMCSimulator(
        L=L,
        T_min=T_min,
        T_max=T_max,
        num_replicas=num_replicas,
        algorithm="metropolis_sweep",
        h=0.0,
        replica_seeds=replica_seeds,
    )

    # æ¯ä¸ª L å•ç‹¬ä¸€ä¸ªå­ç›®å½•ï¼Œç”¨äºä¿å­˜ latticesï¼ˆè‹¥å¯ç”¨ï¼‰
    save_dir_L = outdir / f"L{L}"
    save_dir_L.mkdir(parents=True, exist_ok=True)

    sim.run(
        equilibration_steps=int(args.equil_steps),
        production_steps=int(args.prod_steps),
        exchange_interval=int(args.exchange_interval),
        thin=int(args.thin),
        verbose=bool(args.verbose),
        save_lattices=bool(args.save_lattices),
        save_dir=str(save_dir_L),
        worker_id=f"cpu_L{L}",
        auto_thin=bool(getattr(args, "auto_thin", False)),
        thin_min=int(getattr(args, "thin_min", 1)),
        thin_max=int(getattr(args, "thin_max", 10_000)),
        tau_update_interval=int(getattr(args, "tau_update_interval", 256)),
        tau_window=int(getattr(args, "tau_window", 2048)),
    )

    res = sim.analyze(verbose=False)
    return res


# ---------- å°å·¥å…·ï¼šæŒ‰æ¡ç›®æ¢è¡Œæ‰“å° Tc_est ç»“æœ ----------

def _pretty_print_Tc_est(label: str, est: Dict[str, Any]) -> None:
    print(f"[INFO] {label} ç»“æœ:")

    if not isinstance(est, dict):
        print(f"  {est}")
        return

    for key in ("Tc", "var", "std"):
        if key in est:
            print(f"  {key}: {est[key]}")

    if "weights" in est:
        print("  weights:")
        try:
            for w in est["weights"]:
                print(f"    - {w}")
        except TypeError:
            print(f"    {est['weights']}")

    if "pairs" in est:
        print("  pairs:")
        try:
            for pair in est["pairs"]:
                try:
                    L1, L2 = pair
                    print(f"    - ({L1}, {L2})")
                except Exception:
                    print(f"    - {pair}")
        except TypeError:
            print(f"    {est['pairs']}")

    if "crossings" in est:
        print("  crossings:")
        try:
            for c in est["crossings"]:
                try:
                    L1 = getattr(c, "L1", None)
                    L2 = getattr(c, "L2", None)
                    Tc_c = getattr(c, "Tc", None)
                    slope_diff = getattr(c, "slope_diff", None)
                    bracket = getattr(c, "bracket", None)
                    method = getattr(c, "method", "")
                    note = getattr(c, "note", "")

                    line = "    - "
                    if L1 is not None and L2 is not None:
                        line += f"L1={L1}, L2={L2}, "
                    if Tc_c is not None:
                        try:
                            line += f"Tc={Tc_c:.6f}, "
                        except Exception:
                            line += f"Tc={Tc_c}, "
                    if slope_diff is not None:
                        try:
                            line += f"slope_diff={slope_diff:.3f}, "
                        except Exception:
                            line += f"slope_diff={slope_diff}, "
                    if bracket is not None:
                        line += f"bracket={bracket}, "
                    if method:
                        line += f"method={method}"
                    if note:
                        line += f", note={note}"
                    print(line)
                except Exception:
                    print(f"    - {c}")
        except TypeError:
            print(f"    {est['crossings']}")

    for key, value in est.items():
        if key in ("Tc", "var", "std", "weights", "pairs", "crossings"):
            continue
        print(f"  {key}: {value}")


# ---------- åŸºäº raw_results çš„ FSS åˆ†æ ----------

def run_fss_analysis_from_raw(
    results_all_raw: Dict[str, Dict[str, Any]],
    outdir: Path,
    Tc_theory: float = 2.269185,
) -> Dict[str, Any]:
    """
    ä½¿ç”¨åˆå¹¶åçš„ raw_results åš FSS åˆ†æï¼š
      - å…ˆç”¨ to_fss_format è½¬æˆ FSSAnalyzer è¾“å…¥å½¢å¼ï¼›
      - å†è¡¥å…… *_stderr å­—æ®µï¼›
      - ç„¶åè·‘ Tc / Î³/Î½ / æ•°æ®å¡Œç¼©ã€‚
    è¿”å› estimate_Tc('U') çš„å®Œæ•´å­—å…¸ã€‚
    """
    print("\n=== åŸºäºåˆå¹¶åçš„ raw_results æ„å»º FSSAnalyzer ===")

    results_all_fss: Dict[int, Dict[float, Dict[str, Any]]] = {}
    for L_key, block in results_all_raw.items():
        try:
            L_int = int(L_key)
        except Exception:
            continue

        fss_block = to_fss_format(block)

        # ç»™ FSSAnalyzer è¡¥ä¸Š *_stderr å­—æ®µï¼ˆæ²¿ç”¨ *_errï¼‰
        for obs in fss_block.values():
            if not isinstance(obs, dict):
                continue
            for base in ("E", "M", "C", "chi", "U"):
                err_key = f"{base}_err"
                stderr_key = f"{base}_stderr"
                if err_key in obs and stderr_key not in obs:
                    val = obs[err_key]
                    if isinstance(val, (int, float, np.floating)):
                        obs[stderr_key] = float(val)

        results_all_fss[L_int] = fss_block

    if not results_all_fss:
        print("âš ï¸ æ²¡æœ‰å¯ç”¨çš„ FSS æ•°æ®ï¼ˆå¯èƒ½æ‰€æœ‰ L éƒ½ä¸ºç©ºï¼Ÿï¼‰")
        return {}

    analyzer = FSSAnalyzer(results_all_fss, Tc_theory=Tc_theory)

    # 1) Binder U äº¤å‰ â†’ Tc ä¼°è®¡
    Tc_val = None
    Tc_est: Dict[str, Any] = {}
    try:
        est = analyzer.estimate_Tc("U")
        if isinstance(est, dict):
            Tc_est = est
            Tc_val = float(est.get("Tc", None))
            _pretty_print_Tc_est("estimate_Tc('U')", est)
        else:
            Tc_val = float(est)
            Tc_est = {"Tc": Tc_val}
            print(f"[INFO] estimate_Tc('U') å¾—åˆ° Tc â‰ˆ {Tc_val:.6f}")
    except Exception as e:
        print("[WARN] estimate_Tc('U') å¤±è´¥:", e)

    if Tc_val is None:
        Tc_val = Tc_theory
        print(f"[INFO] ä½¿ç”¨ç†è®º Tc = {Tc_val:.6f} ä½œä¸ºåç»­æ‹ŸåˆåŸºå‡†")
    else:
        print(f"[INFO] ä¼°è®¡ Tc â‰ˆ {Tc_val:.6f} (ç†è®ºå€¼ Tcâ‰ˆ{Tc_theory})")

    # 2) ç”¨ Ï‡ çš„ FSS æ‹Ÿåˆ Î³/Î½
    gamma_over_nu = None
    try:
        expo = analyzer.extract_critical_exponents(
            observable="chi",
            Tc_hint=Tc_val,
            fit_nu=False,  # Î½ å·²çŸ¥ä¸º 1 çš„æƒ…å½¢ä¸‹ï¼Œåªæ‹Ÿåˆ Î³/Î½ æ›´ç¨³
        )
        print("exponents (from chi):", expo)

        for k in ["gamma_over_nu", "exponent_ratio", "exponent"]:
            if k in expo:
                gamma_over_nu = float(expo[k])
                print(f"[INFO] è¯†åˆ«åˆ° {k} â‰ˆ {gamma_over_nu:.4f}")
                break
    except TypeError:
        expo = analyzer.extract_critical_exponents("chi")
        print("exponents (from chi):", expo)
        for k in ["gamma_over_nu", "exponent_ratio", "exponent"]:
            if k in expo:
                gamma_over_nu = float(expo[k])
                print(f"[INFO] è¯†åˆ«åˆ° {k} â‰ˆ {gamma_over_nu:.4f}")
                break
    except Exception as e:
        print("[WARN] æå–ä¸´ç•ŒæŒ‡æ•°å¤±è´¥:", e)

    if gamma_over_nu is not None:
        print(
            "[INFO] ç†è®ºå€¼ Î³/Î½ â‰ˆ 1.75; "
            f"å½“å‰æ‹Ÿåˆå¾—åˆ° Î³/Î½ â‰ˆ {gamma_over_nu:.4f}"
        )
        if gamma_over_nu < 0:
            print("[WARN] Î³/Î½ < 0 æ˜æ˜¾è¿èƒŒç‰©ç†å¸¸è¯†ï¼Œè¯´æ˜é‡‡æ ·æˆ–æ‹Ÿåˆè¿˜æœ‰é—®é¢˜ã€‚")
    else:
        print("[WARN] æœªèƒ½ä» expo ä¸­è¯†åˆ«å‡º Î³/Î½ï¼Œåç»­ data collapse å°†ä½¿ç”¨ç†è®ºå€¼ã€‚")
        gamma_over_nu = 1.75

    # 3) åšä¸€æ¬¡ Ï‡ çš„æ•°æ®å¡Œç¼©
    print("\n=== chi æ•°æ®å¡Œç¼© (CPU ç‰ˆ) ===")
    if not hasattr(analyzer, "data_collapse"):
        print("[INFO] å½“å‰ FSSAnalyzer æœªå®ç° data_collapseï¼Œè·³è¿‡è¯¥æ­¥éª¤ã€‚")
    else:
        try:
            collapse = analyzer.data_collapse(
                observable="chi",
                Tc=Tc_val,
                nu=1.0,                # 2D Ising çš„ç†è®º Î½ = 1
                exponent_ratio=gamma_over_nu,
            )
            print("data_collapse keys:", list(collapse.keys()))
            if "score" in collapse:
                print(f"collapse score â‰ˆ {collapse['score']:.6g}")
                print("ï¼ˆscore è¶Šå°é€šå¸¸ä»£è¡¨å¡Œç¼©è´¨é‡è¶Šå¥½ï¼Œä»…ä¾›ç›¸å¯¹æ¯”è¾ƒï¼‰")
        except Exception as e:
            print("[WARN] data_collapse è°ƒç”¨å¤±è´¥:", e)

    # å†™ Tc_est.json
    Tc_path = outdir / "Tc_est.json"
    try:
        with open(Tc_path, "w", encoding="utf-8") as f:
            json.dump(Tc_est, f, indent=2, default=json_default, ensure_ascii=False)
        print(f"âœ… Tc ä¼°è®¡ä¸é…å¯¹ crossing ä¿¡æ¯å·²å†™å…¥ {Tc_path}")
    except Exception as exc:
        print(f"âŒ å†™ Tc_est.json å¤±è´¥: {exc}")

    return Tc_est


# ---------- mainï¼šæ•´ä½“ç®¡çº¿ ----------

def main():
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument("--L_list", type=int, nargs="+", default=[16, 32, 64],
                        help="è¦è·‘çš„ L åˆ—è¡¨ï¼Œä¾‹å¦‚: --L_list 16 32 64")
    parser.add_argument("--outdir", default="runs/cpu_large_scale_fss",
                        help="è¾“å‡ºç›®å½•ï¼ˆraw_results.json / Tc_est.json / lattices ç­‰ï¼‰")

    # ç‰©ç† & æ¨¡æ‹Ÿå‚æ•°ï¼ˆé»˜è®¤å–ä½ åŸæ¥ demo çš„é‚£ä¸€ç»„ï¼‰
    parser.add_argument("--T_min", type=float, default=2.1)
    parser.add_argument("--T_max", type=float, default=2.5)
    parser.add_argument("--num_replicas", type=int, default=16)

    parser.add_argument("--equil_steps", type=int, default=20_000,
                        help="é¢„çƒ­æ­¥æ•°ï¼ˆsweepsï¼‰")
    parser.add_argument("--prod_steps", type=int, default=100_000,
                        help="ç”Ÿäº§é˜¶æ®µæ€» sweeps æ•°ï¼ˆä¸åŒ…å«é¢„çƒ­ï¼‰")
    parser.add_argument("--exchange_interval", type=int, default=5,
                        help="æ¯éš”å¤šå°‘ sweeps å°è¯•ä¸€æ¬¡ replica äº¤æ¢")

    #  parser.add_argument("--thin", type=int, default=20,
    #                      help="åˆå§‹ thinning é—´éš”ï¼ˆsweepsï¼‰ã€‚è‹¥ --auto_thinï¼Œåˆ™ä½œä¸ºèµ·å§‹ thinã€‚")
    parser.add_argument("--thin", type=int, default=200,
                        help="åˆå§‹ thinning é—´éš”ï¼ˆsweepsï¼‰ã€‚è‹¥ --auto_thinï¼Œåˆ™ä½œä¸ºèµ·å§‹ thinã€‚")

    # è‡ªé€‚åº” thin ç›¸å…³å‚æ•°ï¼ˆHybridREMCSimulator ä¹Ÿæ”¯æŒï¼‰
    parser.add_argument("--auto_thin", action="store_true",
                        help="å¯ç”¨åœ¨çº¿ä¼°è®¡ Ï„_int çš„è‡ªé€‚åº” thinningã€‚")
    parser.add_argument("--thin_min", type=int, default=1,
                        help="è‡ªé€‚åº” thinning çš„æœ€å°å€¼ï¼ˆå•ä½ï¼šsweepsï¼‰ã€‚")
    parser.add_argument("--thin_max", type=int, default=10_000,
                        help="è‡ªé€‚åº” thinning çš„æœ€å¤§å€¼ï¼ˆå•ä½ï¼šsweepsï¼‰ã€‚")
    parser.add_argument("--tau_update_interval", type=int, default=256,
                        help="æ¯éš”å¤šå°‘ä¸ª production sweeps åšä¸€æ¬¡ Ï„_int æ›´æ–°ã€‚")
    parser.add_argument("--tau_window", type=int, default=2048,
                        help="ä¼°è®¡ Ï„_int æ—¶ä½¿ç”¨çš„çª—å£é•¿åº¦ï¼ˆæœ€å¤§å†å²æ ·æœ¬æ•°ï¼‰ã€‚")

    # I/O & å…¶å®ƒ
    parser.add_argument("--save_lattices", action="store_true",
                        help="æ˜¯å¦æŠŠ lattice è½¨è¿¹å†™å…¥ HDF5ï¼ˆæ¯ä¸ªæ¸©åº¦ä¸€ä¸ªæ–‡ä»¶ï¼‰ã€‚")
    parser.add_argument("--verbose", action="store_true",
                        help="æ‰“å°ä¸€äº›è¿›åº¦ä¿¡æ¯ã€‚")

    args = parser.parse_args()

    outdir = Path(args.outdir)
    outdir.mkdir(parents=True, exist_ok=True)

    print("=" * 70)
    print("CPU REMC â†’ FSSAnalyzer â†’ Tc / Î³/Î½ / æ•°æ®å¡Œç¼©")
    print("=" * 70)
    print(
        f"å‚æ•°æ¦‚è§ˆï¼šL_list={args.L_list}, Tâˆˆ[{args.T_min},{args.T_max}], "
        f"replicas={args.num_replicas}, equil={args.equil_steps}, prod={args.prod_steps}, thin={args.thin}"
    )

    # ---------- è¯»å–æ—§çš„ raw_results.jsonï¼ˆç”¨äºåˆå¹¶æ ·æœ¬ï¼‰ ----------
    raw_path = outdir / "raw_results.json"
    prev_all_raw: Dict[str, Any] = {}
    if raw_path.exists():
        try:
            with open(raw_path, "r", encoding="utf-8") as f:
                prev_all_raw = json.load(f)
            if not isinstance(prev_all_raw, dict):
                prev_all_raw = {}
        except Exception as exc:
            print(f"âš ï¸ è¯»å–å·²æœ‰ raw_results.json å¤±è´¥ï¼Œå°†ä»ç©ºç™½å¼€å§‹: {exc}")
            prev_all_raw = {}
    else:
        prev_all_raw = {}

    # ---------- æœ¬æ¬¡ run çš„ï¼ˆæˆ–åˆå¹¶åçš„ï¼‰ç»“æœ ----------
    results_all_raw: Dict[str, Dict[str, Any]] = {}

    for L in args.L_list:
        print(f"\n=== REMC for L={L} ===")
        res_new = run_one_L(L, outdir, args)

        L_key = str(L)
        if L_key in prev_all_raw:
            print(f"[L={L}] ğŸ”„ ä¸ raw_results.json ä¸­æ—§æ ·æœ¬è¿›è¡Œåˆå¹¶ï¼ˆè¿½åŠ æ¨¡å¼ï¼‰")
            merged = merge_analyze_for_one_L(prev_all_raw[L_key], res_new, L)
        else:
            merged = res_new

        results_all_raw[L_key] = merged

    # æŠŠè¿™æ¬¡æ²¡æœ‰è·‘åˆ°çš„ Lï¼ˆä½†æ—§ç»“æœé‡Œå­˜åœ¨çš„ï¼‰æ¬è¿‡æ¥
    for L_key, block in prev_all_raw.items():
        if L_key not in results_all_raw:
            results_all_raw[L_key] = block

    # ---------- å†™å›åˆå¹¶åçš„ raw_results.json ----------
    try:
        with open(raw_path, "w", encoding="utf-8") as f:
            json.dump(results_all_raw, f, indent=2, default=json_default, ensure_ascii=False)
        print(f"âœ… åˆå¹¶åçš„ç»Ÿè®¡ç»“æœå·²å†™å…¥ {raw_path}")
    except Exception as exc:
        print(f"âŒ å†™ raw_results.json å¤±è´¥: {exc}")
        return

    # ---------- FSS åˆ†æ ----------
    Tc_est = run_fss_analysis_from_raw(results_all_raw, outdir=outdir)
    print("Done. See", outdir)


if __name__ == "__main__":
    main()

